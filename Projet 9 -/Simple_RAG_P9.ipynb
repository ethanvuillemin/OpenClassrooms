{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf1017a1",
   "metadata": {},
   "source": [
    "# Rag Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd728ec",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda14ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "class RAGState(TypedDict):\n",
    "    \"\"\"Shared state\"\"\"\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    retrieved_docs: List[Document]\n",
    "    answer: str\n",
    "    error: str | None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296b0f0",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da39499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle d'embeddings simple et gratuit\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# LLM pour la génération\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Template de prompt simple\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Tu es un assistant qui répond aux questions en utilisant UNIQUEMENT les documents fournis. Si l'information n'est pas dans les documents, dis-le clairement.\"),\n",
    "    (\"user\", \"\"\"Documents:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Réponds de manière concise et précise.\"\"\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74371b9e",
   "metadata": {},
   "source": [
    "# Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d61128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_documents(state: RAGState) -> RAGState:\n",
    "    \"\"\"Découpe les documents en chunks\"\"\"\n",
    "    print(\"Chunking des documents...\")\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    chunks = splitter.split_documents(state[\"documents\"])\n",
    "    state[\"documents\"] = chunks\n",
    "    print(f\"{len(chunks)} chunks créés\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def create_vectorstore(state: RAGState) -> RAGState:\n",
    "    \"\"\"Crée la base vectorielle et indexe les documents\"\"\"\n",
    "    print(\"Création de la base vectorielle...\")\n",
    "    \n",
    "    # Création de l'index FAISS\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        state[\"documents\"],\n",
    "        embeddings\n",
    "    )\n",
    "    \n",
    "    # Stockage dans l'état (en production, utiliser une DB persistante)\n",
    "    state[\"vectorstore\"] = vectorstore\n",
    "    print(\"Base vectorielle créée\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def retrieve_documents(state: RAGState) -> RAGState:\n",
    "    \"\"\"Recherche les documents pertinents\"\"\"\n",
    "    print(f\"Recherche pour: '{state['question']}'\")\n",
    "    \n",
    "    vectorstore = state.get(\"vectorstore\")\n",
    "    if not vectorstore:\n",
    "        state[\"error\"] = \"Base vectorielle non initialisée\"\n",
    "        return state\n",
    "    \n",
    "    # Recherche par similarité (top 3)\n",
    "    docs = vectorstore.similarity_search(\n",
    "        state[\"question\"],\n",
    "        k=3\n",
    "    )\n",
    "    \n",
    "    state[\"retrieved_docs\"] = docs\n",
    "    print(f\"{len(docs)} documents récupérés\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def generate_answer(state: RAGState) -> RAGState:\n",
    "    \"\"\"Génère la réponse avec le LLM\"\"\"\n",
    "    print(\"Génération de la réponse...\")\n",
    "    \n",
    "    if not state[\"retrieved_docs\"]:\n",
    "        state[\"answer\"] = \"Je n'ai pas trouvé d'informations pertinentes dans les documents.\"\n",
    "        return state\n",
    "    \n",
    "    # Prépare le contexte\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"Document {i+1}:\\n{doc.page_content}\"\n",
    "        for i, doc in enumerate(state[\"retrieved_docs\"])\n",
    "    ])\n",
    "    \n",
    "    # Génère la réponse\n",
    "    chain = prompt_template | llm\n",
    "    response = chain.invoke({\n",
    "        \"context\": context,\n",
    "        \"question\": state[\"question\"]\n",
    "    })\n",
    "    \n",
    "    state[\"answer\"] = response.content\n",
    "    print(\"Réponse générée\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bcab82",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df48188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_rag_graph():\n",
    "    \"\"\"Crée le graphe RAG simple\"\"\"\n",
    "    \n",
    "    workflow = StateGraph(RAGState)\n",
    "    \n",
    "    # Ajout des nœuds\n",
    "    workflow.add_node(\"chunk\", chunk_documents)\n",
    "    workflow.add_node(\"vectorize\", create_vectorstore)\n",
    "    workflow.add_node(\"retrieve\", retrieve_documents)\n",
    "    workflow.add_node(\"generate\", generate_answer)\n",
    "    \n",
    "    # Définition du flux\n",
    "    workflow.set_entry_point(\"chunk\")\n",
    "    workflow.add_edge(\"chunk\", \"vectorize\")\n",
    "    workflow.add_edge(\"vectorize\", \"retrieve\")\n",
    "    workflow.add_edge(\"retrieve\", \"generate\")\n",
    "    workflow.add_edge(\"generate\", END)\n",
    "    \n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8679d67",
   "metadata": {},
   "source": [
    "## Test du workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927b5c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Exemple de documents\n",
    "    sample_docs = [\n",
    "        Document(\n",
    "            page_content=\"\"\"\n",
    "            Article 1101 du Code civil :\n",
    "            Le contrat est un accord de volontés entre deux ou plusieurs personnes destiné à créer, modifier, transmettre ou éteindre des obligations.\n",
    "            \"\"\",\n",
    "            metadata={\n",
    "                \"source\": \"code_civil.txt\",\n",
    "                \"article\": \"1101\",\n",
    "                \"section\": \"Des contrats\",\n",
    "                \"thème\": \"Définition du contrat\"\n",
    "            }\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"\"\"\n",
    "            Article 1102 du Code civil :\n",
    "            Le contrat est synallagmatique ou unilateral selon que les contractants s'obligent réciproquement les uns envers les autres ou que l'un d'eux s'engage envers l'autre sans que celui-ci s'engage.\n",
    "            \"\"\",\n",
    "            metadata={\n",
    "                \"source\": \"code_civil.txt\",\n",
    "                \"article\": \"1102\",\n",
    "                \"section\": \"Des contrats\",\n",
    "                \"thème\": \"Types de contrats\"\n",
    "            }\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"\"\"\n",
    "            Article 1103 du Code civil :\n",
    "            Les contrats légalement formés tiennent lieu de loi à ceux qui les ont faits. Ils ne peuvent être révoqués que de leur consentement mutuel, ou pour les causes que la loi autorise.\n",
    "            \"\"\",\n",
    "            metadata={\n",
    "                \"source\": \"code_civil.txt\",\n",
    "                \"article\": \"1103\",\n",
    "                \"section\": \"Des contrats\",\n",
    "                \"thème\": \"Force obligatoire du contrat\"\n",
    "            }\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"\"\"\n",
    "            Article 1104 du Code civil :\n",
    "            Les contrats doivent être négociés, formés et exécutés de bonne foi. Cette disposition est d'ordre public.\n",
    "            \"\"\",\n",
    "            metadata={\n",
    "                \"source\": \"code_civil.txt\",\n",
    "                \"article\": \"1104\",\n",
    "                \"section\": \"Des contrats\",\n",
    "                \"thème\": \"Bonne foi\"\n",
    "            }\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"\"\"\n",
    "            Article 1231-1 du Code civil :\n",
    "            L'obligation est une contrainte juridique en vertu de laquelle une personne, le débiteur, est tenue d'accomplir une prestation au profit d'une autre, le créancier.\n",
    "            \"\"\",\n",
    "            metadata={\n",
    "                \"source\": \"code_civil.txt\",\n",
    "                \"article\": \"1231-1\",\n",
    "                \"section\": \"Des obligations\",\n",
    "                \"thème\": \"Définition de l'obligation\"\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Création du graphe\n",
    "    app = create_simple_rag_graph()\n",
    "    \n",
    "    # État initial (avec documents pré-chargés)\n",
    "    initial_state = {\n",
    "        \"question\": \"Quelle est la politique de remboursement ?\",\n",
    "        \"documents\": sample_docs,\n",
    "        \"retrieved_docs\": [],\n",
    "        \"answer\": \"\",\n",
    "        \"error\": None\n",
    "    }\n",
    "    \n",
    "    # Exécution\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RAG SIMPLE - DÉMONSTRATION\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    result = app.invoke(initial_state)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RÉSULTAT\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nQuestion: {result['question']}\")\n",
    "    print(f\"\\nRéponse:\\n{result['answer']}\")\n",
    "    print(f\"\\nDocuments utilisés: {len(result['retrieved_docs'])}\")\n",
    "    \n",
    "    # Test d'une autre question\n",
    "    print(\"\\n\\n\" + \"=\"*60)\n",
    "    print(\"NOUVELLE QUESTION\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Pour une nouvelle question, on réutilise la vectorstore\n",
    "    new_state = {\n",
    "        \"question\": \"Quelles sont les garanties du pack Premium ?\",\n",
    "        \"documents\": [],\n",
    "        \"retrieved_docs\": [],\n",
    "        \"answer\": \"\",\n",
    "        \"error\": None,\n",
    "        \"vectorstore\": result.get(\"vectorstore\")  # Réutilisation\n",
    "    }\n",
    "    \n",
    "    # On skip les étapes de chunking et vectorization\n",
    "    retrieval_workflow = StateGraph(RAGState)\n",
    "    retrieval_workflow.add_node(\"retrieve\", retrieve_documents)\n",
    "    retrieval_workflow.add_node(\"generate\", generate_answer)\n",
    "    retrieval_workflow.set_entry_point(\"retrieve\")\n",
    "    retrieval_workflow.add_edge(\"retrieve\", \"generate\")\n",
    "    retrieval_workflow.add_edge(\"generate\", END)\n",
    "    \n",
    "    retrieval_app = retrieval_workflow.compile()\n",
    "    result2 = retrieval_app.invoke(new_state)\n",
    "    \n",
    "    print(f\"Question: {result2['question']}\")\n",
    "    print(f\"\\nRéponse:\\n{result2['answer']}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
