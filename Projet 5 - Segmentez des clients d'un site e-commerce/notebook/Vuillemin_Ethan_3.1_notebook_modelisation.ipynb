{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook de modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des dataframes RFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
       "      <td>2018-05-10 10:56:27</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>141.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0000b849f77a49e4a4ce2b2a4ca5be3f</td>\n",
       "      <td>2018-05-07 11:11:27</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>27.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0000f46a3911fa3c0805444483337064</td>\n",
       "      <td>2017-03-10 21:05:03</td>\n",
       "      <td>585</td>\n",
       "      <td>1</td>\n",
       "      <td>86.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0000f6ccb0745a6a4b88665a16c9f078</td>\n",
       "      <td>2017-10-12 20:29:41</td>\n",
       "      <td>369</td>\n",
       "      <td>1</td>\n",
       "      <td>43.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0004aac84e0df4da2b147fca70cf8255</td>\n",
       "      <td>2017-11-14 19:45:42</td>\n",
       "      <td>336</td>\n",
       "      <td>1</td>\n",
       "      <td>196.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                customer_unique_id order_purchase_timestamp    R  \\\n",
       "0           0  0000366f3b9a7992bf8c76cfdf3221e2      2018-05-10 10:56:27  160   \n",
       "1           1  0000b849f77a49e4a4ce2b2a4ca5be3f      2018-05-07 11:11:27  163   \n",
       "2           2  0000f46a3911fa3c0805444483337064      2017-03-10 21:05:03  585   \n",
       "3           3  0000f6ccb0745a6a4b88665a16c9f078      2017-10-12 20:29:41  369   \n",
       "4           4  0004aac84e0df4da2b147fca70cf8255      2017-11-14 19:45:42  336   \n",
       "\n",
       "   F       M  \n",
       "0  1  141.90  \n",
       "1  1   27.19  \n",
       "2  1   86.22  \n",
       "3  1   43.62  \n",
       "4  1  196.89  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfm = pd.read_csv('../data/dataset_rfm.csv')\n",
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>S</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
       "      <td>2018-05-10 10:56:27</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>141.90</td>\n",
       "      <td>5</td>\n",
       "      <td>cajamar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0000b849f77a49e4a4ce2b2a4ca5be3f</td>\n",
       "      <td>2018-05-07 11:11:27</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>27.19</td>\n",
       "      <td>4</td>\n",
       "      <td>osasco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0000f46a3911fa3c0805444483337064</td>\n",
       "      <td>2017-03-10 21:05:03</td>\n",
       "      <td>585</td>\n",
       "      <td>1</td>\n",
       "      <td>86.22</td>\n",
       "      <td>3</td>\n",
       "      <td>sao jose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0000f6ccb0745a6a4b88665a16c9f078</td>\n",
       "      <td>2017-10-12 20:29:41</td>\n",
       "      <td>369</td>\n",
       "      <td>1</td>\n",
       "      <td>43.62</td>\n",
       "      <td>4</td>\n",
       "      <td>belem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0004aac84e0df4da2b147fca70cf8255</td>\n",
       "      <td>2017-11-14 19:45:42</td>\n",
       "      <td>336</td>\n",
       "      <td>1</td>\n",
       "      <td>196.89</td>\n",
       "      <td>5</td>\n",
       "      <td>sorocaba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                customer_unique_id order_purchase_timestamp    R  \\\n",
       "0           0  0000366f3b9a7992bf8c76cfdf3221e2      2018-05-10 10:56:27  160   \n",
       "1           1  0000b849f77a49e4a4ce2b2a4ca5be3f      2018-05-07 11:11:27  163   \n",
       "2           2  0000f46a3911fa3c0805444483337064      2017-03-10 21:05:03  585   \n",
       "3           3  0000f6ccb0745a6a4b88665a16c9f078      2017-10-12 20:29:41  369   \n",
       "4           4  0004aac84e0df4da2b147fca70cf8255      2017-11-14 19:45:42  336   \n",
       "\n",
       "   F       M  S         L  \n",
       "0  1  141.90  5   cajamar  \n",
       "1  1   27.19  4    osasco  \n",
       "2  1   86.22  3  sao jose  \n",
       "3  1   43.62  4     belem  \n",
       "4  1  196.89  5  sorocaba  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfmls  = pd.read_csv('../data/dataset_rfm_ls.csv')\n",
    "rfmls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark des models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pycaret.clustering import setup, create_model, ClusteringExperiment, pull\n",
    "\n",
    "# # Initialisation de l'environnement PyCaret pour le clustering\n",
    "# exp_clu = setup(\n",
    "#     data=rfm.dropna(), \n",
    "#     use_gpu = True,\n",
    "#     ignore_features= ['customer_unique_id', 'order_purchase_timestamp'],\n",
    "#     preprocess=True, \n",
    "#     experiment_name=\"benchmark_clustering_model\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_testing(modelname):\n",
    "#     print(\"---------------------------\")\n",
    "#     dbscan = create_model(modelname)\n",
    "#     pull(dbscan)\n",
    "#     print(dbscan)\n",
    "#     print(\"---#---#---#---#---#---#---\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['dbscan', 'optics', 'meanshift','ap', 'sc', 'hclust', 'kmeans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn import cluster, metrics\n",
    "# from sklearn.datasets import make_blobs\n",
    "# import time\n",
    "# import hdbscan  # Pour HDBSCAN\n",
    "\n",
    "\n",
    "# rfm = rfm.drop(['customer_unique_id', 'order_purchase_timestamp'], axis=1).dropna()\n",
    "# rfm_sample = rfm.sample(frac=0.1, random_state=42)  # Prend 10% des données\n",
    "# print(rfm_sample.shape)\n",
    "# # Liste des algorithmes à comparer\n",
    "# model_list = {\n",
    "#     'dbscan': cluster.DBSCAN(eps=0.5, min_samples=5),\n",
    "#     'optics': cluster.OPTICS(min_samples=5),\n",
    "#     'meanshift': cluster.MeanShift(),\n",
    "#     'ap': cluster.AffinityPropagation(),\n",
    "#     'sc': cluster.SpectralClustering(n_clusters=3, assign_labels='discretize'),\n",
    "#     'hclust': cluster.AgglomerativeClustering(n_clusters=3),\n",
    "#     'kmeans': cluster.KMeans(n_clusters=3),\n",
    "#     'hdbscan':hdbscan.HDBSCAN(min_cluster_size=5)\n",
    "# }\n",
    "\n",
    "# # Tableau pour stocker les résultats\n",
    "# results = []\n",
    "\n",
    "# # Évaluation des algorithmes\n",
    "# for name, algorithm in model_list.items():\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     # Fit et prédire les labels\n",
    "#     labels = algorithm.fit_predict(rfm_sample)\n",
    "#     elapsed_time = time.time() - start_time\n",
    "    \n",
    "#     # Calcul des scores\n",
    "#     silhouette_score = metrics.silhouette_score(rfm_sample,labels)if len(set(labels)) > 1 else None\n",
    "#     davies_bouldin_score = metrics.davies_bouldin_score(rfm_sample,labels) if len(set(labels)) > 1 else None\n",
    "#     calinski_harabasz_score = metrics.calinski_harabasz_score(rfm_sample,labels) if len(set(labels)) > 1 else None\n",
    "\n",
    "#     results.append({\n",
    "#         \"Algorithm\": name,\n",
    "#         \"Time (s)\": elapsed_time,\n",
    "#         \"Silhouette Score\": silhouette_score,\n",
    "#         \"Davies-Bouldin Score\": davies_bouldin_score,\n",
    "#         \"Calinski-Harabasz Score\": calinski_harabasz_score\n",
    "#     })\n",
    "\n",
    "# # Création d'un DataFrame pour afficher les résultats\n",
    "# results_df = pd.DataFrame(results)\n",
    "# print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn import cluster, metrics\n",
    "import hdbscan  # Pour HDBSCAN\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import hdbscan\n",
    "import skfuzzy as fuzz  # Pour Fuzzy C-Means\n",
    "\n",
    "# Chargement des données (exemple)\n",
    "# rfm = pd.read_csv(\"data.csv\")  # Décommenter pour charger un dataset réel\n",
    "\n",
    "# Suppression de colonnes non pertinentes et valeurs manquantes\n",
    "rfm = rfm.drop(['customer_unique_id', 'order_purchase_timestamp'], axis=1).dropna()\n",
    "\n",
    "# Échantillonnage si le dataset est trop grand (> 10 000 lignes)\n",
    "if rfm.shape[0] > 10000:\n",
    "    rfm_sample = rfm.sample(frac=0.1, random_state=42)\n",
    "else:\n",
    "    rfm_sample = rfm\n",
    "\n",
    "\n",
    "# if np.isnan(rfm_sample).any() or np.isinf(rfm_sample).any():\n",
    "#     print(\"Attention : NaN ou Inf détectés dans les données !\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "rfm_sample_scaled = scaler.fit_transform(rfm_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Liste des algorithmes à comparer (avec optimisation)\n",
    "model_list = {\n",
    "    # Basés sur la densité\n",
    "    'dbscan': cluster.DBSCAN(eps=0.5, min_samples=5),\n",
    "    'optics': cluster.OPTICS(min_samples=5),\n",
    "    'hdbscan': hdbscan.HDBSCAN(min_cluster_size=5),\n",
    "\n",
    "    # Basés sur les centroïdes\n",
    "    'kmeans': cluster.KMeans(n_clusters=3, n_init='auto'),\n",
    "    'minibatch_kmeans': cluster.MiniBatchKMeans(n_clusters=3, n_init='auto'),\n",
    "    'kmedoids': KMedoids(n_clusters=3, random_state=42),\n",
    "\n",
    "    # Basés sur la hiérarchie\n",
    "    'hclust': cluster.AgglomerativeClustering(n_clusters=3),\n",
    "    'birch': cluster.Birch(n_clusters=3),\n",
    "\n",
    "    # Basés sur les graphes\n",
    "    'spectral': cluster.SpectralClustering(n_clusters=3, assign_labels='discretize'),\n",
    "    'ap': cluster.AffinityPropagation(),\n",
    "\n",
    "    # Basés sur la distribution\n",
    "    'gmm': GaussianMixture(n_components=3, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Limiter certains algorithmes coûteux si le dataset est petit\n",
    "if rfm_sample_scaled.shape[0] < 5000:\n",
    "    model_list.update({\n",
    "        'meanshift': cluster.MeanShift(),\n",
    "        'ap': cluster.AffinityPropagation(),\n",
    "        'sc': cluster.SpectralClustering(n_clusters=3, assign_labels='discretize')\n",
    "    })\n",
    "\n",
    "# Fonction d'évaluation des algorithmes\n",
    "def evaluate_algorithm(name, algorithm, rfm):\n",
    "    print(f\"Exécution de {name}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Fit et prédire les labels\n",
    "    labels = algorithm.fit_predict(rfm)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Vérification du nombre de clusters\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "    if n_clusters > 1:\n",
    "        silhouette_score = metrics.silhouette_score(rfm, labels)\n",
    "        davies_bouldin_score = metrics.davies_bouldin_score(rfm, labels)\n",
    "        calinski_harabasz_score = metrics.calinski_harabasz_score(rfm, labels)\n",
    "    else:\n",
    "        silhouette_score = davies_bouldin_score = calinski_harabasz_score = None\n",
    "\n",
    "    return {\n",
    "        \"Algorithm\": name,\n",
    "        \"Time (s)\": round(elapsed_time, 3),\n",
    "        \"Clusters\": n_clusters,\n",
    "        \"Silhouette Score\": silhouette_score,\n",
    "        \"Davies-Bouldin Score\": davies_bouldin_score,\n",
    "        \"Calinski-Harabasz Score\": calinski_harabasz_score\n",
    "    }\n",
    "\n",
    "# Exécution parallèle des algorithmes\n",
    "results = Parallel(n_jobs=-1)(delayed(evaluate_algorithm)(name, algo, rfm_sample_scaled) for name, algo in model_list.items())\n",
    "\n",
    "# Création du DataFrame des résultats\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Affichage des résultats triés par Silhouette Score\n",
    "results_df.sort_values(by=\"Silhouette Score\", ascending=False, na_position='last')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_p5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
