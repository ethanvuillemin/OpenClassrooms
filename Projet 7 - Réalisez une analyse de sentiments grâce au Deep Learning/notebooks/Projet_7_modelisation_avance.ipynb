{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc1_'></a>[Modèle sur mesure avancé](#toc0_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "- [Modèle sur mesure avancé](#toc1_)    \n",
        "- [Telechargements & imports des données](#toc2_)    \n",
        "- [Preprocessing des données](#toc3_)    \n",
        "  - [Renommer les colonnes](#toc3_1_)    \n",
        "  - [Text cleaning](#toc3_2_)    \n",
        "  - [Fonctions de split](#toc3_3_)    \n",
        "    - [Lemmatisation](#toc3_3_1_)    \n",
        "    - [Stemmatisation](#toc3_3_2_)    \n",
        "    - [Tokenisation](#toc3_3_3_)    \n",
        "  - [Definir Features et Target](#toc3_4_)    \n",
        "  - [Embedding et vectorisation](#toc3_5_)    \n",
        "    - [keras embedding](#toc3_5_1_)    \n",
        "    - [Glove Embedding](#toc3_5_2_)    \n",
        "- [Modelisation](#toc4_)    \n",
        "  - [Log des Models avec MlFlow](#toc4_1_)    \n",
        "  - [Creations des modèles](#toc4_2_)    \n",
        "    - [RNN](#toc4_2_1_)    \n",
        "    - [LSTM](#toc4_2_2_)    \n",
        "    - [LSTM BIDIRECTIONEL](#toc4_2_3_)    \n",
        "  - [Entrainement et evaluation des modèles](#toc4_3_)    \n",
        "    - [Tokenisation avec Keras](#toc4_3_1_)    \n",
        "    - [Tokenisation avec Glove](#toc4_3_2_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=false\n",
        "\tanchor=true\n",
        "\tflat=false\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc2_'></a>[Telechargements & imports des données](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install uv\n",
        "!uv pip install pandas numpy matplotlib scikit-learn wordcloud tqdm sentence_transformers ipykernel tensorflow spacy mlflow\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coyG-vruyiKu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "import string\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import mlflow\n",
        "import mlflow.tensorflow\n",
        "import nltk\n",
        "import spacy\n",
        "import tensorflow as tf\n",
        "from nltk.stem.snowball import PorterStemmer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics import (\n",
        "    average_precision_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import mlflow.tensorflow\n",
        "import pandas as pd\n",
        "from mlflow.models.signature import infer_signature\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    average_precision_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tensorflow.keras.layers import (\n",
        "    LSTM,\n",
        "    Bidirectional,\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    Embedding,\n",
        "    SimpleRNN,\n",
        ")\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb-eVtvpxyBL",
        "outputId": "243edbab-b4db-4eb1-e5e4-db209da2b315"
      },
      "outputs": [],
      "source": [
        "# Telecharger les données\n",
        "!wget https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/AI+Engineer/Project+7%C2%A0-+D%C3%A9tectez+les+Bad+Buzz+gr%C3%A2ce+au+Deep+Learning/sentiment140.zip\n",
        "\n",
        "# Extraction des données\n",
        "ZIP_PATH = '/content/sentiment140.zip'\n",
        "!unzip $ZIP_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lecture du Dataframe\n",
        "DATASET_PATH = '/content/training.1600000.processed.noemoticon.csv'\n",
        "df = pd.read_csv(DATASET_PATH, sep=',', encoding = \"ISO-8859-1\", header=None)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc3_'></a>[Preprocessing des données](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_1_'></a>[Renommer les colonnes](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Renommer les colonnes en ce basant sur les cards du dataset\n",
        "df = df.rename(columns={\n",
        "    df.columns[0]: 'target',\n",
        "    df.columns[1]: 'ids',\n",
        "    df.columns[2]: 'date',\n",
        "    df.columns[3]: 'flag',\n",
        "    df.columns[4]: 'user',\n",
        "    df.columns[5]: 'text',\n",
        "\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir les jeux de données\n",
        "\n",
        "complete_df = df[['target', 'text']]\n",
        "sample_df = df[['target', 'text']].sample(16_000)\n",
        "\n",
        "# Afficher la valeurs des labels initiaux\n",
        "print(sample_df['target'].value_counts())\n",
        "\n",
        "# Conversion en binaire 0,1\n",
        "sample_df['target'] = sample_df['target'].replace({0: 0, 4: 1})\n",
        "complete_df['target'] = complete_df['target'].replace({0: 0, 4: 1})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_2_'></a>[Text cleaning](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def tweet_cleaning(tweet):\n",
        "    \"\"\"\n",
        "    Nettoie et prétraite un tweet\n",
        "\n",
        "    Cette fonction effectue plusieurs étapes de nettoyage :\n",
        "        - Suppression des URLs, mentions et hashtags\n",
        "        - Suppression des emojis et caractères spéciaux\n",
        "        - Suppression de la ponctuation et des chiffres\n",
        "        - Normalisation du texte (minuscules, espaces multiples)\n",
        "\n",
        "    Params :\n",
        "        tweet (str) : Le tweet brut à nettoyer.\n",
        "\n",
        "    Return :\n",
        "        str : Le tweet nettoyé et prétraité, prêt pour l'analyse de sentiment.\n",
        "\n",
        "    \"\"\"\n",
        "    # Supprimer les URLs\n",
        "    tweet = re.sub(r'https?://\\S+|www\\.\\S+', '', tweet)\n",
        "\n",
        "    # Supprimer les mentions (@user)\n",
        "    tweet = re.sub(r'@\\w+', '', tweet)\n",
        "\n",
        "    # Supprimer les hashtags (#hashtag)\n",
        "    tweet = re.sub(r'#\\w+', '', tweet)\n",
        "\n",
        "    # Normaliser & supprimer les caractères\n",
        "    tweet = tweet.encode('ascii', 'ignore').decode('utf-8')\n",
        "    tweet = re.sub(r'[^\\x00-\\x7F]+', '', tweet)\n",
        "\n",
        "    # Supprimer la ponctuation\n",
        "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Supprimer les chiffres\n",
        "    tweet = re.sub(r'\\d+', '', tweet)\n",
        "\n",
        "    # Supprimer les espaces multiples et les espaces au début/fin\n",
        "    tweet = re.sub(r'\\s+', ' ', tweet).strip()\n",
        "\n",
        "    return tweet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# appliquer la fonction a la colonne text\n",
        "sample_df.apply(lambda x: tweet_cleaning(x['text']), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_3_'></a>[Fonctions de split](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_3_1_'></a>[Lemmatisation](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lemmatize_text(text):\n",
        "    doc = nlp(text)\n",
        "    return [token.lemma_ for token in doc]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_3_2_'></a>[Stemmatisation](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stem_text_french(text):\n",
        "    tokens = nltk.word_tokenize(text, language='french')\n",
        "    return [stemmer.stem(token) for token in tokens]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_3_3_'></a>[Tokenisation](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_text(text):\n",
        "    doc = nlp(text)\n",
        "    return [token.text for token in doc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple de resultat sur 1 sample\n",
        "text = sample_df['text'].sample(1).values[0]\n",
        "print(text)\n",
        "\n",
        "print(lemmatize_text(text=text))\n",
        "print(stem_text_french(text=text))\n",
        "print(tokenize_text(text=text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_4_'></a>[Definir Features et Target](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = sample_df['text'].apply(tweet_cleaning)\n",
        "y = sample_df['target']\n",
        "\n",
        "# Diviser les données en ensembles d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_5_'></a>[Embedding et vectorisation](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_5_1_'></a>[keras embedding](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=10_000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Padding\n",
        "MAX_LEN = 100\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_5_2_'></a>[Glove Embedding](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -O glove6b100dtxt.zip https://www.kaggle.com/api/v1/datasets/download/danielwillgeorge/glove6b100dtxt\n",
        "!unzip glove6b100dtxt.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Charger les embeddings GloVe\n",
        "def load_glove_embeddings(glove_file):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file, encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    return embeddings_index\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "glove_file = 'glove.6B.100d.txt'\n",
        "embeddings_index = load_glove_embeddings(glove_file)\n",
        "\n",
        "# Créer une matrice d'embeddings\n",
        "embedding_matrix = np.zeros((10000, 100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < 10000:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc4_'></a>[Modelisation](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc4_1_'></a>[Log des Models avec MlFlow](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_model_with_mlflow(model, X_train, y_train, X_test, y_test, tags, model_name, model_version=None, experiment_name=\"Modèle sur mesure avancé\", hyperparams=None):\n",
        "    \"\"\"\n",
        "    Enregistre un modèle TensorFlow avec MLflow, incluant les métriques, les hyperparamètres,\n",
        "    les tags et le modèle.\n",
        "\n",
        "    Cette fonction configure une expérience MLflow, démarre une nouvelle exécution, évalue \n",
        "    les performances du modèle sur des données de test, enregistre les métriques clés \n",
        "    (accuracy, precision, recall, F1, ROC AUC, PR AUC), les hyperparamètres, les tags \n",
        "    ainsi que le modèle au format MLflow.\n",
        "\n",
        "    Args:\n",
        "        model (tf.keras.Model): Modèle TensorFlow à logger.\n",
        "        X_train (array-like or pd.DataFrame): Données d'entraînement utilisées pour inférer la signature du modèle.\n",
        "        y_train (array-like or pd.Series): Labels d'entraînement (utilisés uniquement pour l'évaluation si nécessaire).\n",
        "        X_test (array-like or pd.DataFrame): Données de test pour l'évaluation du modèle.\n",
        "        y_test (array-like or pd.Series): Labels de test pour l'évaluation du modèle.\n",
        "        tags (dict): Dictionnaire de tags supplémentaires à associer à l'exécution MLflow.\n",
        "        model_name (str): Nom du modèle à utiliser comme nom de l'exécution MLflow.\n",
        "        model_version (str, optional): Version du modèle à enregistrer comme tag. Par défaut None.\n",
        "        experiment_name (str, optional): Nom de l'expérience MLflow. Par défaut \"Modèle sur mesure avancé\".\n",
        "        hyperparams (dict, optional): Hyperparamètres du modèle à logger. Si None, tente de les extraire automatiquement.\n",
        "            Si cela échoue, un message est affiché mais l'exécution continue. Par défaut None.\n",
        "\n",
        "    Returns:\n",
        "        None: Les résultats sont directement enregistrés dans MLflow.\n",
        "    \"\"\"\n",
        "    \n",
        "    mlflow.set_experiment(experiment_name)\n",
        "\n",
        "    with mlflow.start_run(run_name=model_name):\n",
        "        # Récupération des hyperparamètres\n",
        "        if hyperparams is None:\n",
        "            hyperparams = {}\n",
        "            try:\n",
        "                config = model.get_config()\n",
        "                hyperparams[\"layers\"] = str(config.get(\"layers\", \"N/A\"))\n",
        "                hyperparams[\"optimizer\"] = str(model.optimizer.get_config())\n",
        "            except Exception as e:\n",
        "                print(f\"Impossible de récupérer les hyperparamètres automatiquement : {e}\")\n",
        "\n",
        "        for key, value in hyperparams.items():\n",
        "            mlflow.log_param(key, value)\n",
        "\n",
        "\n",
        "        # Prédiction des classes et des probabilités\n",
        "        y_pred_proba = model.predict(X_test).ravel()\n",
        "        y_pred_class = (y_pred_proba > 0.5).astype(\"int32\")\n",
        "\n",
        "        # Calcul des métriques\n",
        "        accuracy = accuracy_score(y_test, y_pred_class)\n",
        "        precision = precision_score(y_test, y_pred_class)\n",
        "        recall = recall_score(y_test, y_pred_class)\n",
        "        f1 = f1_score(y_test, y_pred_class)\n",
        "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "        pr_auc = average_precision_score(y_test, y_pred_proba)\n",
        "\n",
        "        # Log des métriques dans MLflow\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "        mlflow.log_metric(\"precision\", precision)\n",
        "        mlflow.log_metric(\"recall\", recall)\n",
        "        mlflow.log_metric(\"f1\", f1)\n",
        "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "        mlflow.log_metric(\"pr_auc\", pr_auc)\n",
        "\n",
        "        # Informations sur le modèle (nom et version)\n",
        "        mlflow.set_tag(\"mlflow.note.content\", model_name)\n",
        "        if model_version:\n",
        "            mlflow.set_tag(\"model_version\", model_version)\n",
        "\n",
        "        # Logger le modèle\n",
        "        signature = infer_signature(X_train[:2], model.predict(X_train[:2]))\n",
        "        input_ex = X_train[:2]\n",
        "        mlflow.tensorflow.log_model(\n",
        "            model, \"model\",\n",
        "            signature=signature,\n",
        "            input_example=input_ex\n",
        "        )\n",
        "\n",
        "        # Ajouter les tags supplémentaires\n",
        "        for key, val in tags.items():\n",
        "            mlflow.set_tag(key, val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pour faire tourner une instance MlFlow sur google Colab\n",
        "\n",
        "# import os\n",
        "\n",
        "# # Vérifie si MLflow tourne déjà (simple check basé sur ps)\n",
        "# status = os.popen(\"ps aux | grep mlflow\").read()\n",
        "# if \"mlflow\" not in status:\n",
        "#     os.system(\"mlflow ui --port 11247 &\")\n",
        "#     print(\"MLflow lancé.\")\n",
        "# else:\n",
        "#     print(\"MLflow déjà en cours.\")\n",
        "\n",
        "# # Affichage du lien\n",
        "# from google.colab.output import eval_js\n",
        "\n",
        "# print(\"🔗 MLflow UI :\", eval_js(\"google.colab.kernel.proxyPort(11247)\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc4_2_'></a>[Creations des modèles](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc4_2_1_'></a>[RNN](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modèle RNN avec Keras Embedding\n",
        "rnn_model_keras = Sequential()\n",
        "rnn_model_keras.add(Embedding(input_dim=10_000, output_dim=128, input_length=MAX_LEN))\n",
        "rnn_model_keras.add(SimpleRNN(128))\n",
        "rnn_model_keras.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "rnn_model_keras.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modèle RNN avec GloVe Embedding\n",
        "rnn_model_glove = Sequential()\n",
        "rnn_model_glove.add(Embedding(input_dim=10_000, output_dim=100, input_length=MAX_LEN, weights=[embedding_matrix], trainable=False))\n",
        "rnn_model_glove.add(SimpleRNN(128))\n",
        "rnn_model_glove.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "rnn_model_glove.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc4_2_2_'></a>[LSTM](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modèle LSTM avec Keras Embedding\n",
        "lstm_model_keras = Sequential()\n",
        "lstm_model_keras.add(Embedding(input_dim=10_000, output_dim=128, input_length=MAX_LEN))\n",
        "lstm_model_keras.add(LSTM(128))\n",
        "lstm_model_keras.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model_keras.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modèle LSTM avec GloVe Embedding\n",
        "lstm_model_glove = Sequential()\n",
        "lstm_model_glove.add(Embedding(input_dim=10_000, output_dim=100, input_length=MAX_LEN, weights=[embedding_matrix], trainable=False))\n",
        "lstm_model_glove.add(LSTM(128))\n",
        "lstm_model_glove.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model_glove.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc4_2_3_'></a>[LSTM BIDIRECTIONEL](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modèle LSTM Bidirectionnel à plusieurs couches avec Keras Embedding\n",
        "lstm_model_bidirectional_keras = Sequential()\n",
        "lstm_model_bidirectional_keras.add(Embedding(input_dim=10000, output_dim=128, input_length=MAX_LEN))\n",
        "lstm_model_bidirectional_keras.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "lstm_model_bidirectional_keras.add(Dropout(0.5))\n",
        "lstm_model_bidirectional_keras.add(Bidirectional(LSTM(64)))\n",
        "lstm_model_bidirectional_keras.add(Dropout(0.5))\n",
        "lstm_model_bidirectional_keras.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model_bidirectional_keras.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modèle LSTM Bidirectionnel à plusieurs couches avec GloVe Embedding\n",
        "lstm_model_bidirectional_glove = Sequential()\n",
        "lstm_model_bidirectional_glove.add(Embedding(input_dim=10000, output_dim=100, input_length=MAX_LEN, weights=[embedding_matrix], trainable=False))\n",
        "lstm_model_bidirectional_glove.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "lstm_model_bidirectional_glove.add(Dropout(0.5))\n",
        "lstm_model_bidirectional_glove.add(Bidirectional(LSTM(64)))\n",
        "lstm_model_bidirectional_glove.add(Dropout(0.5))\n",
        "lstm_model_bidirectional_glove.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model_bidirectional_glove.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc4_3_'></a>[Entrainement et evaluation des modèles](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc4_3_1_'></a>[Tokenisation avec Keras](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entraîner les modèles\n",
        "print('Entrainement du RNN ...')\n",
        "rnn_model_keras.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "rnn_loss_keras, rnn_accuracy_keras = rnn_model_keras.evaluate(X_test_pad, y_test)\n",
        "print(f'RNN Model with Keras Embedding - Loss: {rnn_loss_keras}, Accuracy: {rnn_accuracy_keras}')\n",
        "\n",
        "print('\\n\\nEntrainement du LSTM ...')\n",
        "lstm_model_keras.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "lstm_loss_keras, lstm_accuracy_keras = lstm_model_keras.evaluate(X_test_pad, y_test)\n",
        "print(f'LSTM Model with Keras Embedding - Loss: {lstm_loss_keras}, Accuracy: {lstm_accuracy_keras}')\n",
        "\n",
        "print('\\n\\nEntrainement du LSTM Bidirectionel ...')\n",
        "lstm_model_bidirectional_keras.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "lstm_loss_bidirectional_keras, lstm_accuracy_bidirectional_keras = lstm_model_bidirectional_keras.evaluate(X_test_pad, y_test)\n",
        "print(f'LSTM Bidirectional Model with Keras Embedding - Loss: {lstm_loss_bidirectional_keras}, Accuracy: {lstm_accuracy_bidirectional_keras}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logger les modèles avec MLflow\n",
        "\n",
        "tags = {\n",
        "    \"dataset_used\": \"sentiment140\",\n",
        "    \"embedding_method\": \"Keras_embedding\",\n",
        "    \"preprocessing\": \"tweet_cleaning_function\",\n",
        "    \"sample_size\": str(sample_df.shape[0]),\n",
        "    \"sample_seed\": \"42\",\n",
        "}\n",
        "\n",
        "# RNN\n",
        "log_model_with_mlflow(\n",
        "    model=rnn_model_keras,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"SimpleRNN_keras_embedding\",\n",
        "    model_version=\"1\",\n",
        ")\n",
        "\n",
        "# LSTM\n",
        "log_model_with_mlflow(\n",
        "    model=lstm_model_keras,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"LSTM_keras_embedding\",\n",
        "    model_version=\"1\",\n",
        ")\n",
        "\n",
        "# LSTM-BiDir\n",
        "log_model_with_mlflow(\n",
        "    model=lstm_model_bidirectional_keras,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"Bidirectional_LSTM_keras_embedding\",\n",
        "    model_version=\"1\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc4_3_2_'></a>[Tokenisation avec Glove](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HCJrAiLp77v",
        "outputId": "55036620-1b84-4853-ef65-4de90abf43a2"
      },
      "outputs": [],
      "source": [
        "print('Entrainement du RNN ...')\n",
        "rnn_model_glove.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "rnn_loss_glove, rnn_accuracy_glove = rnn_model_glove.evaluate(X_test_pad, y_test)\n",
        "print(f'RNN Model with GloVe Embedding - Loss: {rnn_loss_glove}, Accuracy: {rnn_accuracy_glove}')\n",
        "\n",
        "print('\\n\\nEntrainement du LSTM ...')\n",
        "lstm_model_glove.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "lstm_loss_glove, lstm_accuracy_glove = lstm_model_glove.evaluate(X_test_pad, y_test)\n",
        "print(f'LSTM Model with GloVe Embedding - Loss: {lstm_loss_glove}, Accuracy: {lstm_accuracy_glove}')\n",
        "\n",
        "\n",
        "print('\\n\\nEntrainement du LSTM Bidirectionel ...')\n",
        "lstm_model_bidirectional_glove.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "lstm_loss_bidirectional_glove, lstm_accuracy_bidirectional_glove = lstm_model_bidirectional_glove.evaluate(X_test_pad, y_test)\n",
        "print(f'LSTM Bidirectional Model with GloVe Embedding - Loss: {lstm_loss_bidirectional_glove}, Accuracy: {lstm_accuracy_bidirectional_glove}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX-vkkrFtj3Y",
        "outputId": "1d1556b8-5f74-4f2f-bd6d-c1fefcc60a07"
      },
      "outputs": [],
      "source": [
        "# Logger les modèles avec MLflow\n",
        "\n",
        "tags = {\n",
        "    \"dataset_used\": \"sentiment140\",\n",
        "    \"embedding_method\": \"Glove_embedding\",\n",
        "    \"preprocessing\": \"tweet_cleaning_function\",\n",
        "    \"sample_size\": str(sample_df.shape[0]),\n",
        "    \"sample_seed\": \"42\",\n",
        "}\n",
        "\n",
        "# RNN\n",
        "log_model_with_mlflow(\n",
        "    model=rnn_model_glove,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"SimpleRNN_glove_embdding\",\n",
        "    model_version=\"1\",\n",
        ")\n",
        "\n",
        "# LSTM\n",
        "log_model_with_mlflow(\n",
        "    model=lstm_model_glove,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"LSTM_glove_embdding\",\n",
        "    model_version=\"1\",\n",
        ")\n",
        "\n",
        "# LSTM-BiDir\n",
        "log_model_with_mlflow(\n",
        "    model=lstm_model_bidirectional_glove,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"Bidirectional_LSTM_glove_embdding\",\n",
        "    model_version=\"1\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "O5nIy0Vn6MDa",
        "outputId": "d021c39e-9e0f-4f4c-f83f-68b38f4a57fa"
      },
      "outputs": [],
      "source": [
        "# Pour telecharger le dossier mlruns depuis colab\n",
        "# import shutil\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "# # Chemin du dossier à télécharger\n",
        "# dossier_a_telecharger = '/content/mlruns'\n",
        "\n",
        "# # Nom du fichier zip\n",
        "# nom_zip = 'mlruns_avance.zip'\n",
        "\n",
        "# # Créer une archive zip\n",
        "# shutil.make_archive(nom_zip.split('.')[0], 'zip', dossier_a_telecharger)\n",
        "\n",
        "# # Télécharger le fichier zip\n",
        "# files.download(nom_zip)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
