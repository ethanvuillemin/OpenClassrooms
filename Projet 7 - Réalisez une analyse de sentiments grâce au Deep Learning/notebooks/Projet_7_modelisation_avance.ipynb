{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc1_'></a>[Mod√®le sur mesure avanc√©](#toc0_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "- [Mod√®le sur mesure avanc√©](#toc1_)    \n",
        "- [Telechargements & imports des donn√©es](#toc2_)    \n",
        "- [Preprocessing des donn√©es](#toc3_)    \n",
        "  - [Renommer les colonnes](#toc3_1_)    \n",
        "  - [Text cleaning](#toc3_2_)    \n",
        "  - [Fonctions de split](#toc3_3_)    \n",
        "    - [Lemmatisation](#toc3_3_1_)    \n",
        "    - [Stemmatisation](#toc3_3_2_)    \n",
        "    - [Tokenisation](#toc3_3_3_)    \n",
        "  - [Definir Features et Target](#toc3_4_)    \n",
        "  - [Embedding et vectorisation](#toc3_5_)    \n",
        "    - [keras embedding](#toc3_5_1_)    \n",
        "    - [Glove Embedding](#toc3_5_2_)    \n",
        "- [Modelisation](#toc4_)    \n",
        "  - [Log des Models avec MlFlow](#toc4_1_)    \n",
        "  - [Creations des mod√®les](#toc4_2_)    \n",
        "    - [RNN](#toc4_2_1_)    \n",
        "    - [LSTM](#toc4_2_2_)    \n",
        "    - [LSTM BIDIRECTIONEL](#toc4_2_3_)    \n",
        "  - [Entrainement et evaluation des mod√®les](#toc4_3_)    \n",
        "    - [Tokenisation avec Keras](#toc4_3_1_)    \n",
        "    - [Tokenisation avec Glove](#toc4_3_2_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=false\n",
        "\tanchor=true\n",
        "\tflat=false\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc2_'></a>[Telechargements & imports des donn√©es](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install uv\n",
        "!uv pip install pandas numpy matplotlib scikit-learn wordcloud tqdm sentence_transformers ipykernel tensorflow spacy mlflow\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coyG-vruyiKu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "import string\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import mlflow\n",
        "import mlflow.tensorflow\n",
        "import nltk\n",
        "import spacy\n",
        "import tensorflow as tf\n",
        "from nltk.stem.snowball import PorterStemmer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics import (\n",
        "    average_precision_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import mlflow.tensorflow\n",
        "import pandas as pd\n",
        "from mlflow.models.signature import infer_signature\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    average_precision_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tensorflow.keras.layers import (\n",
        "    LSTM,\n",
        "    Bidirectional,\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    Embedding,\n",
        "    SimpleRNN,\n",
        ")\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb-eVtvpxyBL",
        "outputId": "243edbab-b4db-4eb1-e5e4-db209da2b315"
      },
      "outputs": [],
      "source": [
        "# Telecharger les donn√©es\n",
        "!wget https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/AI+Engineer/Project+7%C2%A0-+D%C3%A9tectez+les+Bad+Buzz+gr%C3%A2ce+au+Deep+Learning/sentiment140.zip\n",
        "\n",
        "# Extraction des donn√©es\n",
        "ZIP_PATH = '/content/sentiment140.zip'\n",
        "!unzip $ZIP_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lecture du Dataframe\n",
        "DATASET_PATH = '/content/training.1600000.processed.noemoticon.csv'\n",
        "df = pd.read_csv(DATASET_PATH, sep=',', encoding = \"ISO-8859-1\", header=None)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc3_'></a>[Preprocessing des donn√©es](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_1_'></a>[Renommer les colonnes](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Renommer les colonnes en ce basant sur les cards du dataset\n",
        "df = df.rename(columns={\n",
        "    df.columns[0]: 'target',\n",
        "    df.columns[1]: 'ids',\n",
        "    df.columns[2]: 'date',\n",
        "    df.columns[3]: 'flag',\n",
        "    df.columns[4]: 'user',\n",
        "    df.columns[5]: 'text',\n",
        "\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir les jeux de donn√©es\n",
        "\n",
        "complete_df = df[['target', 'text']]\n",
        "sample_df = df[['target', 'text']].sample(16_000)\n",
        "\n",
        "# Afficher la valeurs des labels initiaux\n",
        "print(sample_df['target'].value_counts())\n",
        "\n",
        "# Conversion en binaire 0,1\n",
        "sample_df['target'] = sample_df['target'].replace({0: 0, 4: 1})\n",
        "complete_df['target'] = complete_df['target'].replace({0: 0, 4: 1})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_2_'></a>[Text cleaning](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def tweet_cleaning(tweet):\n",
        "    \"\"\"\n",
        "    Nettoie et pr√©traite un tweet\n",
        "\n",
        "    Cette fonction effectue plusieurs √©tapes de nettoyage :\n",
        "        - Suppression des URLs, mentions et hashtags\n",
        "        - Suppression des emojis et caract√®res sp√©ciaux\n",
        "        - Suppression de la ponctuation et des chiffres\n",
        "        - Normalisation du texte (minuscules, espaces multiples)\n",
        "\n",
        "    Params :\n",
        "        tweet (str) : Le tweet brut √† nettoyer.\n",
        "\n",
        "    Return :\n",
        "        str : Le tweet nettoy√© et pr√©trait√©, pr√™t pour l'analyse de sentiment.\n",
        "\n",
        "    \"\"\"\n",
        "    # Supprimer les URLs\n",
        "    tweet = re.sub(r'https?://\\S+|www\\.\\S+', '', tweet)\n",
        "\n",
        "    # Supprimer les mentions (@user)\n",
        "    tweet = re.sub(r'@\\w+', '', tweet)\n",
        "\n",
        "    # Supprimer les hashtags (#hashtag)\n",
        "    tweet = re.sub(r'#\\w+', '', tweet)\n",
        "\n",
        "    # Normaliser & supprimer les caract√®res\n",
        "    tweet = tweet.encode('ascii', 'ignore').decode('utf-8')\n",
        "    tweet = re.sub(r'[^\\x00-\\x7F]+', '', tweet)\n",
        "\n",
        "    # Supprimer la ponctuation\n",
        "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Supprimer les chiffres\n",
        "    tweet = re.sub(r'\\d+', '', tweet)\n",
        "\n",
        "    # Supprimer les espaces multiples et les espaces au d√©but/fin\n",
        "    tweet = re.sub(r'\\s+', ' ', tweet).strip()\n",
        "\n",
        "    return tweet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# appliquer la fonction a la colonne text\n",
        "sample_df.apply(lambda x: tweet_cleaning(x['text']), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_3_'></a>[Fonctions de split](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_3_1_'></a>[Lemmatisation](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lemmatize_text(text):\n",
        "    doc = nlp(text)\n",
        "    return [token.lemma_ for token in doc]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_3_2_'></a>[Stemmatisation](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stem_text_french(text):\n",
        "    tokens = nltk.word_tokenize(text, language='french')\n",
        "    return [stemmer.stem(token) for token in tokens]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_3_3_'></a>[Tokenisation](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_text(text):\n",
        "    doc = nlp(text)\n",
        "    return [token.text for token in doc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple de resultat sur 1 sample\n",
        "text = sample_df['text'].sample(1).values[0]\n",
        "print(text)\n",
        "\n",
        "print(lemmatize_text(text=text))\n",
        "print(stem_text_french(text=text))\n",
        "print(tokenize_text(text=text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_4_'></a>[Definir Features et Target](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = sample_df['text'].apply(tweet_cleaning)\n",
        "y = sample_df['target']\n",
        "\n",
        "# Diviser les donn√©es en ensembles d'entra√Ænement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_5_'></a>[Embedding et vectorisation](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_5_1_'></a>[keras embedding](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=10_000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Padding\n",
        "MAX_LEN = 100\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_5_2_'></a>[Glove Embedding](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -O glove6b100dtxt.zip https://www.kaggle.com/api/v1/datasets/download/danielwillgeorge/glove6b100dtxt\n",
        "!unzip glove6b100dtxt.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Charger les embeddings GloVe\n",
        "def load_glove_embeddings(glove_file):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file, encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    return embeddings_index\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "glove_file = 'glove.6B.100d.txt'\n",
        "embeddings_index = load_glove_embeddings(glove_file)\n",
        "\n",
        "# Cr√©er une matrice d'embeddings\n",
        "embedding_matrix = np.zeros((10000, 100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < 10000:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc4_'></a>[Modelisation](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc4_1_'></a>[Log des Models avec MlFlow](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_model_with_mlflow(model, X_train, y_train, X_test, y_test, tags, model_name, model_version=None, experiment_name=\"Mod√®le sur mesure avanc√©\", hyperparams=None):\n",
        "    \"\"\"\n",
        "    Enregistre un mod√®le TensorFlow avec MLflow, incluant les m√©triques, les hyperparam√®tres,\n",
        "    les tags et le mod√®le.\n",
        "\n",
        "    Cette fonction configure une exp√©rience MLflow, d√©marre une nouvelle ex√©cution, √©value \n",
        "    les performances du mod√®le sur des donn√©es de test, enregistre les m√©triques cl√©s \n",
        "    (accuracy, precision, recall, F1, ROC AUC, PR AUC), les hyperparam√®tres, les tags \n",
        "    ainsi que le mod√®le au format MLflow.\n",
        "\n",
        "    Args:\n",
        "        model (tf.keras.Model): Mod√®le TensorFlow √† logger.\n",
        "        X_train (array-like or pd.DataFrame): Donn√©es d'entra√Ænement utilis√©es pour inf√©rer la signature du mod√®le.\n",
        "        y_train (array-like or pd.Series): Labels d'entra√Ænement (utilis√©s uniquement pour l'√©valuation si n√©cessaire).\n",
        "        X_test (array-like or pd.DataFrame): Donn√©es de test pour l'√©valuation du mod√®le.\n",
        "        y_test (array-like or pd.Series): Labels de test pour l'√©valuation du mod√®le.\n",
        "        tags (dict): Dictionnaire de tags suppl√©mentaires √† associer √† l'ex√©cution MLflow.\n",
        "        model_name (str): Nom du mod√®le √† utiliser comme nom de l'ex√©cution MLflow.\n",
        "        model_version (str, optional): Version du mod√®le √† enregistrer comme tag. Par d√©faut None.\n",
        "        experiment_name (str, optional): Nom de l'exp√©rience MLflow. Par d√©faut \"Mod√®le sur mesure avanc√©\".\n",
        "        hyperparams (dict, optional): Hyperparam√®tres du mod√®le √† logger. Si None, tente de les extraire automatiquement.\n",
        "            Si cela √©choue, un message est affich√© mais l'ex√©cution continue. Par d√©faut None.\n",
        "\n",
        "    Returns:\n",
        "        None: Les r√©sultats sont directement enregistr√©s dans MLflow.\n",
        "    \"\"\"\n",
        "    \n",
        "    mlflow.set_experiment(experiment_name)\n",
        "\n",
        "    with mlflow.start_run(run_name=model_name):\n",
        "        # R√©cup√©ration des hyperparam√®tres\n",
        "        if hyperparams is None:\n",
        "            hyperparams = {}\n",
        "            try:\n",
        "                config = model.get_config()\n",
        "                hyperparams[\"layers\"] = str(config.get(\"layers\", \"N/A\"))\n",
        "                hyperparams[\"optimizer\"] = str(model.optimizer.get_config())\n",
        "            except Exception as e:\n",
        "                print(f\"Impossible de r√©cup√©rer les hyperparam√®tres automatiquement : {e}\")\n",
        "\n",
        "        for key, value in hyperparams.items():\n",
        "            mlflow.log_param(key, value)\n",
        "\n",
        "\n",
        "        # Pr√©diction des classes et des probabilit√©s\n",
        "        y_pred_proba = model.predict(X_test).ravel()\n",
        "        y_pred_class = (y_pred_proba > 0.5).astype(\"int32\")\n",
        "\n",
        "        # Calcul des m√©triques\n",
        "        accuracy = accuracy_score(y_test, y_pred_class)\n",
        "        precision = precision_score(y_test, y_pred_class)\n",
        "        recall = recall_score(y_test, y_pred_class)\n",
        "        f1 = f1_score(y_test, y_pred_class)\n",
        "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "        pr_auc = average_precision_score(y_test, y_pred_proba)\n",
        "\n",
        "        # Log des m√©triques dans MLflow\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "        mlflow.log_metric(\"precision\", precision)\n",
        "        mlflow.log_metric(\"recall\", recall)\n",
        "        mlflow.log_metric(\"f1\", f1)\n",
        "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "        mlflow.log_metric(\"pr_auc\", pr_auc)\n",
        "\n",
        "        # Informations sur le mod√®le (nom et version)\n",
        "        mlflow.set_tag(\"mlflow.note.content\", model_name)\n",
        "        if model_version:\n",
        "            mlflow.set_tag(\"model_version\", model_version)\n",
        "\n",
        "        # Logger le mod√®le\n",
        "        signature = infer_signature(X_train[:2], model.predict(X_train[:2]))\n",
        "        input_ex = X_train[:2]\n",
        "        mlflow.tensorflow.log_model(\n",
        "            model, \"model\",\n",
        "            signature=signature,\n",
        "            input_example=input_ex\n",
        "        )\n",
        "\n",
        "        # Ajouter les tags suppl√©mentaires\n",
        "        for key, val in tags.items():\n",
        "            mlflow.set_tag(key, val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pour faire tourner une instance MlFlow sur google Colab\n",
        "\n",
        "# import os\n",
        "\n",
        "# # V√©rifie si MLflow tourne d√©j√† (simple check bas√© sur ps)\n",
        "# status = os.popen(\"ps aux | grep mlflow\").read()\n",
        "# if \"mlflow\" not in status:\n",
        "#     os.system(\"mlflow ui --port 11247 &\")\n",
        "#     print(\"MLflow lanc√©.\")\n",
        "# else:\n",
        "#     print(\"MLflow d√©j√† en cours.\")\n",
        "\n",
        "# # Affichage du lien\n",
        "# from google.colab.output import eval_js\n",
        "\n",
        "# print(\"üîó MLflow UI :\", eval_js(\"google.colab.kernel.proxyPort(11247)\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc4_2_'></a>[Creations des mod√®les](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc4_2_1_'></a>[RNN](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mod√®le RNN avec Keras Embedding\n",
        "rnn_model_keras = Sequential()\n",
        "rnn_model_keras.add(Embedding(input_dim=10_000, output_dim=128, input_length=MAX_LEN))\n",
        "rnn_model_keras.add(SimpleRNN(128))\n",
        "rnn_model_keras.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "rnn_model_keras.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mod√®le RNN avec GloVe Embedding\n",
        "rnn_model_glove = Sequential()\n",
        "rnn_model_glove.add(Embedding(input_dim=10_000, output_dim=100, input_length=MAX_LEN, weights=[embedding_matrix], trainable=False))\n",
        "rnn_model_glove.add(SimpleRNN(128))\n",
        "rnn_model_glove.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "rnn_model_glove.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc4_2_2_'></a>[LSTM](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mod√®le LSTM avec Keras Embedding\n",
        "lstm_model_keras = Sequential()\n",
        "lstm_model_keras.add(Embedding(input_dim=10_000, output_dim=128, input_length=MAX_LEN))\n",
        "lstm_model_keras.add(LSTM(128))\n",
        "lstm_model_keras.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model_keras.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mod√®le LSTM avec GloVe Embedding\n",
        "lstm_model_glove = Sequential()\n",
        "lstm_model_glove.add(Embedding(input_dim=10_000, output_dim=100, input_length=MAX_LEN, weights=[embedding_matrix], trainable=False))\n",
        "lstm_model_glove.add(LSTM(128))\n",
        "lstm_model_glove.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model_glove.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc4_2_3_'></a>[LSTM BIDIRECTIONEL](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mod√®le LSTM Bidirectionnel √† plusieurs couches avec Keras Embedding\n",
        "lstm_model_bidirectional_keras = Sequential()\n",
        "lstm_model_bidirectional_keras.add(Embedding(input_dim=10000, output_dim=128, input_length=MAX_LEN))\n",
        "lstm_model_bidirectional_keras.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "lstm_model_bidirectional_keras.add(Dropout(0.5))\n",
        "lstm_model_bidirectional_keras.add(Bidirectional(LSTM(64)))\n",
        "lstm_model_bidirectional_keras.add(Dropout(0.5))\n",
        "lstm_model_bidirectional_keras.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model_bidirectional_keras.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mod√®le LSTM Bidirectionnel √† plusieurs couches avec GloVe Embedding\n",
        "lstm_model_bidirectional_glove = Sequential()\n",
        "lstm_model_bidirectional_glove.add(Embedding(input_dim=10000, output_dim=100, input_length=MAX_LEN, weights=[embedding_matrix], trainable=False))\n",
        "lstm_model_bidirectional_glove.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "lstm_model_bidirectional_glove.add(Dropout(0.5))\n",
        "lstm_model_bidirectional_glove.add(Bidirectional(LSTM(64)))\n",
        "lstm_model_bidirectional_glove.add(Dropout(0.5))\n",
        "lstm_model_bidirectional_glove.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model_bidirectional_glove.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc4_3_'></a>[Entrainement et evaluation des mod√®les](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc4_3_1_'></a>[Tokenisation avec Keras](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entra√Æner les mod√®les\n",
        "print('Entrainement du RNN ...')\n",
        "rnn_model_keras.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "rnn_loss_keras, rnn_accuracy_keras = rnn_model_keras.evaluate(X_test_pad, y_test)\n",
        "print(f'RNN Model with Keras Embedding - Loss: {rnn_loss_keras}, Accuracy: {rnn_accuracy_keras}')\n",
        "\n",
        "print('\\n\\nEntrainement du LSTM ...')\n",
        "lstm_model_keras.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "lstm_loss_keras, lstm_accuracy_keras = lstm_model_keras.evaluate(X_test_pad, y_test)\n",
        "print(f'LSTM Model with Keras Embedding - Loss: {lstm_loss_keras}, Accuracy: {lstm_accuracy_keras}')\n",
        "\n",
        "print('\\n\\nEntrainement du LSTM Bidirectionel ...')\n",
        "lstm_model_bidirectional_keras.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "lstm_loss_bidirectional_keras, lstm_accuracy_bidirectional_keras = lstm_model_bidirectional_keras.evaluate(X_test_pad, y_test)\n",
        "print(f'LSTM Bidirectional Model with Keras Embedding - Loss: {lstm_loss_bidirectional_keras}, Accuracy: {lstm_accuracy_bidirectional_keras}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logger les mod√®les avec MLflow\n",
        "\n",
        "tags = {\n",
        "    \"dataset_used\": \"sentiment140\",\n",
        "    \"embedding_method\": \"Keras_embedding\",\n",
        "    \"preprocessing\": \"tweet_cleaning_function\",\n",
        "    \"sample_size\": str(sample_df.shape[0]),\n",
        "    \"sample_seed\": \"42\",\n",
        "}\n",
        "\n",
        "# RNN\n",
        "log_model_with_mlflow(\n",
        "    model=rnn_model_keras,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"SimpleRNN_keras_embedding\",\n",
        "    model_version=\"1\",\n",
        ")\n",
        "\n",
        "# LSTM\n",
        "log_model_with_mlflow(\n",
        "    model=lstm_model_keras,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"LSTM_keras_embedding\",\n",
        "    model_version=\"1\",\n",
        ")\n",
        "\n",
        "# LSTM-BiDir\n",
        "log_model_with_mlflow(\n",
        "    model=lstm_model_bidirectional_keras,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"Bidirectional_LSTM_keras_embedding\",\n",
        "    model_version=\"1\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc4_3_2_'></a>[Tokenisation avec Glove](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HCJrAiLp77v",
        "outputId": "55036620-1b84-4853-ef65-4de90abf43a2"
      },
      "outputs": [],
      "source": [
        "print('Entrainement du RNN ...')\n",
        "rnn_model_glove.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "rnn_loss_glove, rnn_accuracy_glove = rnn_model_glove.evaluate(X_test_pad, y_test)\n",
        "print(f'RNN Model with GloVe Embedding - Loss: {rnn_loss_glove}, Accuracy: {rnn_accuracy_glove}')\n",
        "\n",
        "print('\\n\\nEntrainement du LSTM ...')\n",
        "lstm_model_glove.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "lstm_loss_glove, lstm_accuracy_glove = lstm_model_glove.evaluate(X_test_pad, y_test)\n",
        "print(f'LSTM Model with GloVe Embedding - Loss: {lstm_loss_glove}, Accuracy: {lstm_accuracy_glove}')\n",
        "\n",
        "\n",
        "print('\\n\\nEntrainement du LSTM Bidirectionel ...')\n",
        "lstm_model_bidirectional_glove.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "lstm_loss_bidirectional_glove, lstm_accuracy_bidirectional_glove = lstm_model_bidirectional_glove.evaluate(X_test_pad, y_test)\n",
        "print(f'LSTM Bidirectional Model with GloVe Embedding - Loss: {lstm_loss_bidirectional_glove}, Accuracy: {lstm_accuracy_bidirectional_glove}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX-vkkrFtj3Y",
        "outputId": "1d1556b8-5f74-4f2f-bd6d-c1fefcc60a07"
      },
      "outputs": [],
      "source": [
        "# Logger les mod√®les avec MLflow\n",
        "\n",
        "tags = {\n",
        "    \"dataset_used\": \"sentiment140\",\n",
        "    \"embedding_method\": \"Glove_embedding\",\n",
        "    \"preprocessing\": \"tweet_cleaning_function\",\n",
        "    \"sample_size\": str(sample_df.shape[0]),\n",
        "    \"sample_seed\": \"42\",\n",
        "}\n",
        "\n",
        "# RNN\n",
        "log_model_with_mlflow(\n",
        "    model=rnn_model_glove,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"SimpleRNN_glove_embdding\",\n",
        "    model_version=\"1\",\n",
        ")\n",
        "\n",
        "# LSTM\n",
        "log_model_with_mlflow(\n",
        "    model=lstm_model_glove,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"LSTM_glove_embdding\",\n",
        "    model_version=\"1\",\n",
        ")\n",
        "\n",
        "# LSTM-BiDir\n",
        "log_model_with_mlflow(\n",
        "    model=lstm_model_bidirectional_glove,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"Bidirectional_LSTM_glove_embdding\",\n",
        "    model_version=\"1\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "O5nIy0Vn6MDa",
        "outputId": "d021c39e-9e0f-4f4c-f83f-68b38f4a57fa"
      },
      "outputs": [],
      "source": [
        "# Pour telecharger le dossier mlruns depuis colab\n",
        "# import shutil\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "# # Chemin du dossier √† t√©l√©charger\n",
        "# dossier_a_telecharger = '/content/mlruns'\n",
        "\n",
        "# # Nom du fichier zip\n",
        "# nom_zip = 'mlruns_avance.zip'\n",
        "\n",
        "# # Cr√©er une archive zip\n",
        "# shutil.make_archive(nom_zip.split('.')[0], 'zip', dossier_a_telecharger)\n",
        "\n",
        "# # T√©l√©charger le fichier zip\n",
        "# files.download(nom_zip)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
