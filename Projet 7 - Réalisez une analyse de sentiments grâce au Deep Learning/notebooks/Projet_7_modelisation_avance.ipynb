{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLXNQBFnxujG"
      },
      "source": [
        "# Mod√®le sur mesure avanc√©\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI99vZnFyBqd"
      },
      "source": [
        "# Telechargements & imports des donn√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "u--irfi-yNWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee072c25-c3b3-42a6-9523-c5f951662b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: uv in /usr/local/lib/python3.11/dist-packages (0.7.9)\n",
            "\u001b[2mUsing Python 3.11.12 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m11 packages\u001b[0m \u001b[2min 708ms\u001b[0m\u001b[0m\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install uv\n",
        "!uv pip install pandas numpy matplotlib scikit-learn wordcloud tqdm sentence_transformers ipykernel tensorflow spacy mlflow\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "coyG-vruyiKu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "import string\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import tensorflow as tf\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "import mlflow\n",
        "import mlflow.tensorflow\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb-eVtvpxyBL",
        "outputId": "243edbab-b4db-4eb1-e5e4-db209da2b315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-02 11:42:53--  https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/AI+Engineer/Project+7%C2%A0-+D%C3%A9tectez+les+Bad+Buzz+gr%C3%A2ce+au+Deep+Learning/sentiment140.zip\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.92.16.80, 52.92.1.0, 52.218.44.208, ...\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.92.16.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84855679 (81M) [application/zip]\n",
            "Saving to: ‚Äòsentiment140.zip.1‚Äô\n",
            "\n",
            "sentiment140.zip.1  100%[===================>]  80.92M  24.6MB/s    in 3.3s    \n",
            "\n",
            "2025-06-02 11:42:57 (24.6 MB/s) - ‚Äòsentiment140.zip.1‚Äô saved [84855679/84855679]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Telecharger les donn√©es\n",
        "!wget https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/AI+Engineer/Project+7%C2%A0-+D%C3%A9tectez+les+Bad+Buzz+gr%C3%A2ce+au+Deep+Learning/sentiment140.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz4EGufYx31b",
        "outputId": "88174dd7-fd0e-4b48-d410-60fc8374bc46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/sentiment140.zip\n",
            "replace training.1600000.processed.noemoticon.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: training.1600000.processed.noemoticon.csv  \n"
          ]
        }
      ],
      "source": [
        "# Extraction des donn√©es\n",
        "ZIP_PATH = '/content/sentiment140.zip'\n",
        "\n",
        "!unzip $ZIP_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "8oOWWfGjyR1b",
        "outputId": "3d579855-b2d5-46af-c236-936d3d387041"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0           1                             2         3                4  \\\n",
              "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
              "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
              "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
              "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
              "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
              "\n",
              "                                                   5  \n",
              "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1  is upset that he can't update his Facebook by ...  \n",
              "2  @Kenichan I dived many times for the ball. Man...  \n",
              "3    my whole body feels itchy and like its on fire   \n",
              "4  @nationwideclass no, it's not behaving at all....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7224ba42-1076-41b2-8a71-a7d2be273b66\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7224ba42-1076-41b2-8a71-a7d2be273b66')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7224ba42-1076-41b2-8a71-a7d2be273b66 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7224ba42-1076-41b2-8a71-a7d2be273b66');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-95005536-f8e3-47c4-a638-b0bbca72fb1f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-95005536-f8e3-47c4-a638-b0bbca72fb1f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-95005536-f8e3-47c4-a638-b0bbca72fb1f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# Lecture du Dataframe\n",
        "DATASET_PATH = '/content/training.1600000.processed.noemoticon.csv'\n",
        "df = pd.read_csv(DATASET_PATH, sep=',', encoding = \"ISO-8859-1\", header=None)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeTQhwYDzGEK"
      },
      "source": [
        "# Preprocessing des donn√©es"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSvLU1RXzOk0"
      },
      "source": [
        "## Renommer les colonnes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "JU_xWW52zDb2"
      },
      "outputs": [],
      "source": [
        "# Renommer les colonnes en ce basant sur les cards du dataset\n",
        "df = df.rename(columns={\n",
        "    df.columns[0]: 'target',\n",
        "    df.columns[1]: 'ids',\n",
        "    df.columns[2]: 'date',\n",
        "    df.columns[3]: 'flag',\n",
        "    df.columns[4]: 'user',\n",
        "    df.columns[5]: 'text',\n",
        "\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUwR8TN0zSym",
        "outputId": "4f20ced9-6989-4238-ce67-df0d10e46a0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target\n",
            "4    8057\n",
            "0    7943\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Definir les jeux de donn√©es\n",
        "\n",
        "complete_df = df[['target', 'text']]\n",
        "sample_df = df[['target', 'text']].sample(16_000)\n",
        "\n",
        "# Afficher la valeurs des labels initiaux\n",
        "print(sample_df['target'].value_counts())\n",
        "\n",
        "# Conversion en binaire 0,1\n",
        "sample_df['target'] = sample_df['target'].replace({0: 0, 4: 1})\n",
        "complete_df['target'] = complete_df['target'].replace({0: 0, 4: 1})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb1UxxOAzwT6"
      },
      "source": [
        "## Text cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "mULNofOmzfr-"
      },
      "outputs": [],
      "source": [
        "\n",
        "def tweet_cleaning(tweet):\n",
        "    \"\"\"\n",
        "    Nettoie et pr√©traite un tweet\n",
        "\n",
        "    Cette fonction effectue plusieurs √©tapes de nettoyage :\n",
        "        - Suppression des URLs, mentions et hashtags\n",
        "        - Suppression des emojis et caract√®res sp√©ciaux\n",
        "        - Suppression de la ponctuation et des chiffres\n",
        "        - Normalisation du texte (minuscules, espaces multiples)\n",
        "\n",
        "    Params :\n",
        "        tweet (str) : Le tweet brut √† nettoyer.\n",
        "\n",
        "    Return :\n",
        "        str : Le tweet nettoy√© et pr√©trait√©, pr√™t pour l'analyse de sentiment.\n",
        "\n",
        "    \"\"\"\n",
        "    # Supprimer les URLs\n",
        "    tweet = re.sub(r'https?://\\S+|www\\.\\S+', '', tweet)\n",
        "\n",
        "    # Supprimer les mentions (@user)\n",
        "    tweet = re.sub(r'@\\w+', '', tweet)\n",
        "\n",
        "    # Supprimer les hashtags (#hashtag)\n",
        "    tweet = re.sub(r'#\\w+', '', tweet)\n",
        "\n",
        "    # Normaliser & supprimer les caract√®res\n",
        "    tweet = tweet.encode('ascii', 'ignore').decode('utf-8')\n",
        "    tweet = re.sub(r'[^\\x00-\\x7F]+', '', tweet)\n",
        "\n",
        "    # Supprimer la ponctuation\n",
        "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Supprimer les chiffres\n",
        "    tweet = re.sub(r'\\d+', '', tweet)\n",
        "\n",
        "    # Supprimer les espaces multiples et les espaces au d√©but/fin\n",
        "    tweet = re.sub(r'\\s+', ' ', tweet).strip()\n",
        "\n",
        "    return tweet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "D3ZT4oiR2mvV",
        "outputId": "7bd107c7-6385-4c49-f891-89778fa962f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1157800    yesterday was fricken awesome especially last ...\n",
              "966538                   im updating on an imac at partridge\n",
              "1371094    just Tunak Tunak Tun for the first time in a y...\n",
              "1137888      have fun and take pictures with the beach house\n",
              "519539     every week just lt atashinchi no danshi AND os...\n",
              "                                 ...                        \n",
              "316608     haha youtube is being a betch for me i trued t...\n",
              "54585               all shops are closed tomorrow so go shop\n",
              "840666     NOT looking forward to school tomorrow Had a c...\n",
              "742483     zomg how is it sad that you got a rainy day th...\n",
              "1197971    Thanks Nice to meet you too Ive just spotted y...\n",
              "Length: 16000, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1157800</th>\n",
              "      <td>yesterday was fricken awesome especially last ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>966538</th>\n",
              "      <td>im updating on an imac at partridge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1371094</th>\n",
              "      <td>just Tunak Tunak Tun for the first time in a y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1137888</th>\n",
              "      <td>have fun and take pictures with the beach house</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519539</th>\n",
              "      <td>every week just lt atashinchi no danshi AND os...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316608</th>\n",
              "      <td>haha youtube is being a betch for me i trued t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54585</th>\n",
              "      <td>all shops are closed tomorrow so go shop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840666</th>\n",
              "      <td>NOT looking forward to school tomorrow Had a c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>742483</th>\n",
              "      <td>zomg how is it sad that you got a rainy day th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197971</th>\n",
              "      <td>Thanks Nice to meet you too Ive just spotted y...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16000 rows √ó 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "sample_df.apply(lambda x: tweet_cleaning(x['text']), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48LsI2Zh0fp9"
      },
      "source": [
        "## Tokenisation, Lematisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2IOMZfU1Y7Y",
        "outputId": "a9dde767-9bfb-41f6-f985-7c76061fb992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import nltk\n",
        "from nltk.stem.snowball import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# Charger le mod√®le anglais\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Charger le stemmer anglais\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Ssl5Z5w3zfpg"
      },
      "outputs": [],
      "source": [
        "def lemmatize_text(text):\n",
        "    doc = nlp(text)\n",
        "    return [token.lemma_ for token in doc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "cYu-9Bg_1l0L"
      },
      "outputs": [],
      "source": [
        "def stem_text_french(text):\n",
        "    tokens = nltk.word_tokenize(text, language='french')\n",
        "    return [stemmer.stem(token) for token in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "QBYZnuh1zfnE"
      },
      "outputs": [],
      "source": [
        "def tokenize_text(text):\n",
        "    doc = nlp(text)\n",
        "    return [token.text for token in doc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4RP-dqQ1-Pl",
        "outputId": "4880e87a-60ae-4b9b-f430-ff71707189af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@luckyjack  Hehe! and she didn't reply.   But Hemmingway did.       I have  great balls huh?\n",
            "['@luckyjack', ' ', 'hehe', '!', 'and', 'she', 'do', 'not', 'reply', '.', '  ', 'but', 'Hemmingway', 'do', '.', '      ', 'I', 'have', ' ', 'great', 'ball', 'huh', '?']\n",
            "['@', 'luckyjack', 'hehe', '!', 'and', 'she', 'did', \"n't\", 'repli', '.', 'but', 'hemmingway', 'did', '.', 'i', 'have', 'great', 'ball', 'huh', '?']\n",
            "['@luckyjack', ' ', 'Hehe', '!', 'and', 'she', 'did', \"n't\", 'reply', '.', '  ', 'But', 'Hemmingway', 'did', '.', '      ', 'I', 'have', ' ', 'great', 'balls', 'huh', '?']\n"
          ]
        }
      ],
      "source": [
        "text = sample_df['text'].sample(1).values[0]\n",
        "print(text)\n",
        "\n",
        "print(lemmatize_text(text=text))\n",
        "print(stem_text_french(text=text))\n",
        "print(tokenize_text(text=text))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "84tAn9M6qzzE"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = sample_df['text'].apply(tweet_cleaning)\n",
        "y = sample_df['target']"
      ],
      "metadata": {
        "id": "ep21dayqr5l7"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diviser les donn√©es en ensembles d'entra√Ænement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=10_000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Padding\n",
        "MAX_LEN = 100\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN)"
      ],
      "metadata": {
        "id": "pfUdeUROpjZg"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cve99u-Q21zg"
      },
      "source": [
        "## Embedding et vectorisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O glove6b100dtxt.zip https://www.kaggle.com/api/v1/datasets/download/danielwillgeorge/glove6b100dtxt\n",
        "!unzip glove6b100dtxt.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZmq_KIspgiW",
        "outputId": "b5b1f99d-8302-4060-e6bc-67b7990597a1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-02 12:19:43--  https://www.kaggle.com/api/v1/datasets/download/danielwillgeorge/glove6b100dtxt\n",
            "Resolving www.kaggle.com (www.kaggle.com)... 35.244.233.98\n",
            "Connecting to www.kaggle.com (www.kaggle.com)|35.244.233.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com:443/kaggle-data-sets/715814/1246668/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20250602%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250602T121943Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=a8086048579f702cb062954d9a6e37dac71f7e9cefd3f628b246e80e660db9835a1bd7946fe07b273a2ba1ca5e3663d4b6aea470f51d7e0f9190ad0b1304ae4e831594be197bbbf4722d800cf555d30c12418695e866f9b3922687085dbc247cd20e8725ed17ed987826b8d9d2314ca0599ae109e0183a8524de667867edb3b9f07ff501431dc309114e8090e236344842d3f0525636bbb38571f780762c6fc52639c4f4c7b716bbf052c4c9eb6b5bbcb5e9bda4a3e37e119252303c4f73257582b4e76ae91ac59d32c2dbac527fb5674cc7144b3e5040822361b8e4c7b13e9841efbcfaf101b12408fc9755c232e46135685e9bee4b6db0341821c644934dc7 [following]\n",
            "--2025-06-02 12:19:43--  https://storage.googleapis.com/kaggle-data-sets/715814/1246668/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20250602%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250602T121943Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=a8086048579f702cb062954d9a6e37dac71f7e9cefd3f628b246e80e660db9835a1bd7946fe07b273a2ba1ca5e3663d4b6aea470f51d7e0f9190ad0b1304ae4e831594be197bbbf4722d800cf555d30c12418695e866f9b3922687085dbc247cd20e8725ed17ed987826b8d9d2314ca0599ae109e0183a8524de667867edb3b9f07ff501431dc309114e8090e236344842d3f0525636bbb38571f780762c6fc52639c4f4c7b716bbf052c4c9eb6b5bbcb5e9bda4a3e37e119252303c4f73257582b4e76ae91ac59d32c2dbac527fb5674cc7144b3e5040822361b8e4c7b13e9841efbcfaf101b12408fc9755c232e46135685e9bee4b6db0341821c644934dc7\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.26.207, 172.217.204.207, 172.217.203.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.26.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 137847651 (131M) [application/zip]\n",
            "Saving to: ‚Äòglove6b100dtxt.zip‚Äô\n",
            "\n",
            "glove6b100dtxt.zip  100%[===================>] 131.46M   115MB/s    in 1.1s    \n",
            "\n",
            "2025-06-02 12:19:45 (115 MB/s) - ‚Äòglove6b100dtxt.zip‚Äô saved [137847651/137847651]\n",
            "\n",
            "Archive:  glove6b100dtxt.zip\n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.100d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger les embeddings GloVe\n",
        "def load_glove_embeddings(glove_file):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file, encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    return embeddings_index\n",
        "\n",
        "glove_file = 'glove.6B.100d.txt'\n",
        "embeddings_index = load_glove_embeddings(glove_file)\n",
        "\n",
        "# Cr√©er une matrice d'embeddings\n",
        "embedding_matrix = np.zeros((10000, 100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < 10000:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "qF1xU9J1piFw"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelisation"
      ],
      "metadata": {
        "id": "TU9gKF17plx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dense, Dropout, Bidirectional\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from mlflow.models.signature import infer_signature\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "0PtVxyi5n4lG"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Log des models"
      ],
      "metadata": {
        "id": "zozvwceCnxO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.tensorflow  # ou mlflow.sklearn selon le type de mod√®le\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
        "\n",
        "\n",
        "def log_model_with_mlflow(model, X_train, y_train, X_test, y_test, tags, model_name, model_version=None, experiment_name=\"Mod√®le sur mesure avanc√©\", hyperparams=None):\n",
        "    mlflow.set_experiment(experiment_name)\n",
        "\n",
        "    with mlflow.start_run(run_name=model_name):\n",
        "        # R√©cup√©ration des hyperparam√®tres\n",
        "        if hyperparams is None:\n",
        "            hyperparams = {}\n",
        "            try:\n",
        "                config = model.get_config()\n",
        "                hyperparams[\"layers\"] = str(config.get(\"layers\", \"N/A\"))\n",
        "                hyperparams[\"optimizer\"] = str(model.optimizer.get_config())\n",
        "            except Exception as e:\n",
        "                print(f\"Impossible de r√©cup√©rer les hyperparam√®tres automatiquement : {e}\")\n",
        "\n",
        "        for key, value in hyperparams.items():\n",
        "            mlflow.log_param(key, value)\n",
        "\n",
        "\n",
        "        # Pr√©diction des classes et des probabilit√©s\n",
        "        y_pred_proba = model.predict(X_test).ravel()\n",
        "        y_pred_class = (y_pred_proba > 0.5).astype(\"int32\")\n",
        "\n",
        "        # Calcul des m√©triques\n",
        "        accuracy = accuracy_score(y_test, y_pred_class)\n",
        "        precision = precision_score(y_test, y_pred_class)\n",
        "        recall = recall_score(y_test, y_pred_class)\n",
        "        f1 = f1_score(y_test, y_pred_class)\n",
        "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "        pr_auc = average_precision_score(y_test, y_pred_proba)\n",
        "\n",
        "        # Log des m√©triques dans MLflow\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "        mlflow.log_metric(\"precision\", precision)\n",
        "        mlflow.log_metric(\"recall\", recall)\n",
        "        mlflow.log_metric(\"f1\", f1)\n",
        "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "        mlflow.log_metric(\"pr_auc\", pr_auc)\n",
        "\n",
        "        # Informations sur le mod√®le (nom et version)\n",
        "        mlflow.set_tag(\"mlflow.note.content\", model_name)\n",
        "        if model_version:\n",
        "            mlflow.set_tag(\"model_version\", model_version)\n",
        "\n",
        "        # Logger le mod√®le\n",
        "        signature = infer_signature(X_train[:2], model.predict(X_train[:2]))\n",
        "        input_ex = X_train[:2]\n",
        "        mlflow.tensorflow.log_model(\n",
        "            model, \"model\",\n",
        "            signature=signature,\n",
        "            input_example=input_ex\n",
        "        )\n",
        "\n",
        "        # Ajouter les tags suppl√©mentaires\n",
        "        for key, val in tags.items():\n",
        "            mlflow.set_tag(key, val)"
      ],
      "metadata": {
        "id": "AeD_-n42nwme"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# V√©rifie si MLflow tourne d√©j√† (simple check bas√© sur ps)\n",
        "status = os.popen(\"ps aux | grep mlflow\").read()\n",
        "if \"mlflow\" not in status:\n",
        "    os.system(\"mlflow ui --port 11247 &\")\n",
        "    print(\"MLflow lanc√©.\")\n",
        "else:\n",
        "    print(\"MLflow d√©j√† en cours.\")\n",
        "\n",
        "# Affichage du lien\n",
        "from google.colab.output import eval_js\n",
        "print(\"üîó MLflow UI :\", eval_js(\"google.colab.kernel.proxyPort(11247)\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "-64CugSsuAm3",
        "outputId": "6c5c254f-ba83-4636-bbaf-e81496ca6fcc"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow d√©j√† en cours.\n",
            "üîó MLflow UI : https://11247-m-s-3sd1n8nw4ydbm-d.us-east1-0.prod.colab.dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creations des mod√®les"
      ],
      "metadata": {
        "id": "hW3OpWUBpn7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ],
      "metadata": {
        "id": "u0xeZPBOpwO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mod√®le RNN avec Keras Embedding\n",
        "rnn_model_keras = Sequential()\n",
        "rnn_model_keras.add(Embedding(input_dim=10_000, output_dim=128, input_length=MAX_LEN))\n",
        "rnn_model_keras.add(SimpleRNN(128))\n",
        "rnn_model_keras.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "rnn_model_keras.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "J4H2SwcApqaN"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mod√®le RNN avec GloVe Embedding\n",
        "rnn_model_glove = Sequential()\n",
        "rnn_model_glove.add(Embedding(input_dim=10_000, output_dim=100, input_length=MAX_LEN, weights=[embedding_matrix], trainable=False))\n",
        "rnn_model_glove.add(SimpleRNN(128))\n",
        "rnn_model_glove.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "rnn_model_glove.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9k-HyTZ1psoI"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "5T37WqZTpx3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mod√®le LSTM avec Keras Embedding\n",
        "lstm_model_keras = Sequential()\n",
        "lstm_model_keras.add(Embedding(input_dim=10_000, output_dim=128, input_length=MAX_LEN))\n",
        "lstm_model_keras.add(LSTM(128))\n",
        "lstm_model_keras.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model_keras.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FPtMytRBpuKg"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mod√®le LSTM avec GloVe Embedding\n",
        "lstm_model_glove = Sequential()\n",
        "lstm_model_glove.add(Embedding(input_dim=10_000, output_dim=100, input_length=MAX_LEN, weights=[embedding_matrix], trainable=False))\n",
        "lstm_model_glove.add(LSTM(128))\n",
        "lstm_model_glove.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model_glove.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MaRClxc8pvS2"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM BIDIRECTIONEL"
      ],
      "metadata": {
        "id": "z2s6w3Ekpzj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mod√®le LSTM Bidirectionnel √† plusieurs couches avec Keras Embedding\n",
        "lstm_model_bidirectional_keras = Sequential()\n",
        "lstm_model_bidirectional_keras.add(Embedding(input_dim=10000, output_dim=128, input_length=MAX_LEN))\n",
        "lstm_model_bidirectional_keras.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "lstm_model_bidirectional_keras.add(Dropout(0.5))\n",
        "lstm_model_bidirectional_keras.add(Bidirectional(LSTM(64)))\n",
        "lstm_model_bidirectional_keras.add(Dropout(0.5))\n",
        "lstm_model_bidirectional_keras.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model_bidirectional_keras.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "rTwwKsmbp1-k"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mod√®le LSTM Bidirectionnel √† plusieurs couches avec GloVe Embedding\n",
        "lstm_model_bidirectional_glove = Sequential()\n",
        "lstm_model_bidirectional_glove.add(Embedding(input_dim=10000, output_dim=100, input_length=MAX_LEN, weights=[embedding_matrix], trainable=False))\n",
        "lstm_model_bidirectional_glove.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "lstm_model_bidirectional_glove.add(Dropout(0.5))\n",
        "lstm_model_bidirectional_glove.add(Bidirectional(LSTM(64)))\n",
        "lstm_model_bidirectional_glove.add(Dropout(0.5))\n",
        "lstm_model_bidirectional_glove.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model_bidirectional_glove.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "3EpmedUNp2Th"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrainement et evaluation des mod√®les"
      ],
      "metadata": {
        "id": "Kolp-RvEp3kw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenisation avec Keras"
      ],
      "metadata": {
        "id": "YlYxcsV3p-bG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entra√Æner les mod√®les\n",
        "print('Entrainement du RNN ...')\n",
        "rnn_model_keras.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "rnn_loss_keras, rnn_accuracy_keras = rnn_model_keras.evaluate(X_test_pad, y_test)\n",
        "print(f'RNN Model with Keras Embedding - Loss: {rnn_loss_keras}, Accuracy: {rnn_accuracy_keras}')\n",
        "\n",
        "print('\\n\\nEntrainement du LSTM ...')\n",
        "lstm_model_keras.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "lstm_loss_keras, lstm_accuracy_keras = lstm_model_keras.evaluate(X_test_pad, y_test)\n",
        "print(f'LSTM Model with Keras Embedding - Loss: {lstm_loss_keras}, Accuracy: {lstm_accuracy_keras}')\n",
        "\n",
        "print('\\n\\nEntrainement du LSTM Bidirectionel ...')\n",
        "lstm_model_bidirectional_keras.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "lstm_loss_bidirectional_keras, lstm_accuracy_bidirectional_keras = lstm_model_bidirectional_keras.evaluate(X_test_pad, y_test)\n",
        "print(f'LSTM Bidirectional Model with Keras Embedding - Loss: {lstm_loss_bidirectional_keras}, Accuracy: {lstm_accuracy_bidirectional_keras}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5MXbABap741",
        "outputId": "01d4716a-a34f-4f6d-88ed-c0c7d76a61d0"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrainement du RNN ...\n",
            "Epoch 1/2\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 262ms/step - accuracy: 0.5375 - loss: 0.6875 - val_accuracy: 0.6538 - val_loss: 0.6210\n",
            "Epoch 2/2\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 428ms/step - accuracy: 0.6714 - loss: 0.6054 - val_accuracy: 0.6587 - val_loss: 0.6169\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6586 - loss: 0.6135\n",
            "RNN Model with Keras Embedding - Loss: 0.6169412136077881, Accuracy: 0.6587499976158142\n",
            "\n",
            "\n",
            "Entrainement du LSTM ...\n",
            "Epoch 1/2\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 794ms/step - accuracy: 0.5932 - loss: 0.6630 - val_accuracy: 0.7369 - val_loss: 0.5388\n",
            "Epoch 2/2\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 840ms/step - accuracy: 0.7984 - loss: 0.4511 - val_accuracy: 0.7506 - val_loss: 0.5338\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 128ms/step - accuracy: 0.7542 - loss: 0.5404\n",
            "LSTM Model with Keras Embedding - Loss: 0.5337940454483032, Accuracy: 0.7506250143051147\n",
            "\n",
            "\n",
            "Entrainement du LSTM Bidirectionel ...\n",
            "Epoch 1/2\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 3s/step - accuracy: 0.5440 - loss: 0.6771 - val_accuracy: 0.7013 - val_loss: 0.5829\n",
            "Epoch 2/2\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3s/step - accuracy: 0.7658 - loss: 0.4893 - val_accuracy: 0.7287 - val_loss: 0.5521\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 181ms/step - accuracy: 0.7324 - loss: 0.5567\n",
            "LSTM Bidirectional Model with Keras Embedding - Loss: 0.552127480506897, Accuracy: 0.7287499904632568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logger le mod√®le avec MLflow\n",
        "\n",
        "tags = {\n",
        "    \"dataset_used\": \"sentiment140\",\n",
        "    \"embedding_method\": \"Keras_embedding\",\n",
        "    \"preprocessing\": \"tweet_cleaning_function\",\n",
        "    \"sample_size\": str(sample_df.shape[0]),\n",
        "    \"sample_seed\": \"42\",\n",
        "}\n",
        "\n",
        "# Rnn\n",
        "log_model_with_mlflow(\n",
        "    model=rnn_model_keras,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"SimpleRNN_keras_embedding\",\n",
        "    model_version=\"1\",\n",
        ")\n",
        "\n",
        "# LSTM\n",
        "log_model_with_mlflow(\n",
        "    model=lstm_model_keras,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"LSTM_keras_embedding\",\n",
        "    model_version=\"1\",\n",
        ")\n",
        "\n",
        "# LSTM-BiDir\n",
        "log_model_with_mlflow(\n",
        "    model=lstm_model_bidirectional_keras,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"Bidirectional_LSTM_keras_embedding\",\n",
        "    model_version=\"1\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnmzXV1Ipyro",
        "outputId": "6af31aec-c46a-4efb-c030-4581fd4bdc77"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/06/02 13:43:04 INFO mlflow.tracking.fluent: Experiment with name 'Mod√®le sur mesure avanc√©' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/06/02 13:43:15 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpi485otp0/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/06/02 13:43:31 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp32f0pk21/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/06/02 13:43:31 WARNING mlflow.utils.validation: Param value '[{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (256, 100), 'dtype...' (7651 characters) is truncated to 6000 characters to meet the length limit.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/06/02 13:44:00 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpvyrucn0h/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Entrainement du RNN ...')\n",
        "rnn_model_glove.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "rnn_loss_glove, rnn_accuracy_glove = rnn_model_glove.evaluate(X_test_pad, y_test)\n",
        "print(f'RNN Model with GloVe Embedding - Loss: {rnn_loss_glove}, Accuracy: {rnn_accuracy_glove}')\n",
        "\n",
        "print('\\n\\nEntrainement du LSTM ...')\n",
        "lstm_model_glove.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "lstm_loss_glove, lstm_accuracy_glove = lstm_model_glove.evaluate(X_test_pad, y_test)\n",
        "print(f'LSTM Model with GloVe Embedding - Loss: {lstm_loss_glove}, Accuracy: {lstm_accuracy_glove}')\n",
        "\n",
        "\n",
        "print('\\n\\nEntrainement du LSTM Bidirectionel ...')\n",
        "lstm_model_bidirectional_glove.fit(X_train_pad, y_train, epochs=2, batch_size=256, validation_data=(X_test_pad, y_test))\n",
        "lstm_loss_bidirectional_glove, lstm_accuracy_bidirectional_glove = lstm_model_bidirectional_glove.evaluate(X_test_pad, y_test)\n",
        "print(f'LSTM Bidirectional Model with GloVe Embedding - Loss: {lstm_loss_bidirectional_glove}, Accuracy: {lstm_accuracy_bidirectional_glove}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HCJrAiLp77v",
        "outputId": "55036620-1b84-4853-ef65-4de90abf43a2"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrainement du RNN ...\n",
            "Epoch 1/2\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 176ms/step - accuracy: 0.5538 - loss: 0.6950 - val_accuracy: 0.6409 - val_loss: 0.6366\n",
            "Epoch 2/2\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - accuracy: 0.6645 - loss: 0.6140 - val_accuracy: 0.6631 - val_loss: 0.6098\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6695 - loss: 0.6056\n",
            "RNN Model with GloVe Embedding - Loss: 0.6097938418388367, Accuracy: 0.6631249785423279\n",
            "\n",
            "\n",
            "Entrainement du LSTM ...\n",
            "Epoch 1/2\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 603ms/step - accuracy: 0.6129 - loss: 0.6537 - val_accuracy: 0.6884 - val_loss: 0.5908\n",
            "Epoch 2/2\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 599ms/step - accuracy: 0.7012 - loss: 0.5802 - val_accuracy: 0.6978 - val_loss: 0.5793\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 75ms/step - accuracy: 0.6972 - loss: 0.5845\n",
            "LSTM Model with GloVe Embedding - Loss: 0.5793291926383972, Accuracy: 0.6978124976158142\n",
            "\n",
            "\n",
            "Entrainement du LSTM Bidirectionel ...\n",
            "Epoch 1/2\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 2s/step - accuracy: 0.5799 - loss: 0.6687 - val_accuracy: 0.6837 - val_loss: 0.5981\n",
            "Epoch 2/2\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.6952 - loss: 0.5823 - val_accuracy: 0.7156 - val_loss: 0.5610\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 187ms/step - accuracy: 0.7150 - loss: 0.5688\n",
            "LSTM Bidirectional Model with GloVe Embedding - Loss: 0.5610094666481018, Accuracy: 0.715624988079071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logger le mod√®le avec MLflow\n",
        "\n",
        "tags = {\n",
        "    \"dataset_used\": \"sentiment140\",\n",
        "    \"embedding_method\": \"Glove_embedding\",\n",
        "    \"preprocessing\": \"tweet_cleaning_function\",\n",
        "    \"sample_size\": str(sample_df.shape[0]),\n",
        "    \"sample_seed\": \"42\",\n",
        "}\n",
        "\n",
        "# Rnn\n",
        "log_model_with_mlflow(\n",
        "    model=rnn_model_glove,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"SimpleRNN_glove_embdding\",\n",
        "    model_version=\"1\",\n",
        ")\n",
        "\n",
        "# LSTM\n",
        "log_model_with_mlflow(\n",
        "    model=lstm_model_glove,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"LSTM_glove_embdding\",\n",
        "    model_version=\"1\",\n",
        ")\n",
        "\n",
        "# LSTM-BiDir\n",
        "log_model_with_mlflow(\n",
        "    model=lstm_model_bidirectional_glove,\n",
        "    X_train=X_train_pad,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test_pad,\n",
        "    y_test=y_test,\n",
        "    tags=tags,\n",
        "    model_name=\"Bidirectional_LSTM_glove_embdding\",\n",
        "    model_version=\"1\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX-vkkrFtj3Y",
        "outputId": "1d1556b8-5f74-4f2f-bd6d-c1fefcc60a07"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/06/02 13:50:45 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmprbxl8lzx/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/06/02 13:51:05 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpwab5pz29/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/06/02 13:51:05 WARNING mlflow.utils.validation: Param value '[{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (256, 100), 'dtype...' (7644 characters) is truncated to 6000 characters to meet the length limit.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m100/100\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/06/02 13:51:35 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpxtomftha/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Chemin du dossier √† t√©l√©charger\n",
        "dossier_a_telecharger = '/content/mlruns'\n",
        "\n",
        "# Nom du fichier zip\n",
        "nom_zip = 'mlruns_avance.zip'\n",
        "\n",
        "# Cr√©er une archive zip\n",
        "shutil.make_archive(nom_zip.split('.')[0], 'zip', dossier_a_telecharger)\n",
        "\n",
        "# T√©l√©charger le fichier zip\n",
        "files.download(nom_zip)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "O5nIy0Vn6MDa",
        "outputId": "d021c39e-9e0f-4f4c-f83f-68b38f4a57fa"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_674a968f-5a54-40be-a368-c2891cd05709\", \"mlruns_avance.zip\", 64645729)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}