{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c3f50c1",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Projet 7 : Réalisez une analyse de sentiments grâce au Deep Learning](#toc0_)\n",
    "# <a id='toc2_'></a>[Modèle avancé BERT](#toc0_)\n",
    "\n",
    "[Lien OpenClassroom](https://openclassrooms.com/fr/paths/795/projects/1516/1578-mission)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b20ac77",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    " \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "    numbering=false\n",
    "    anchor=true\n",
    "    flat=false\n",
    "    minLevel=2\n",
    "    maxLevel=6\n",
    "    /vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d6b16",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc1_'></a>[Imports](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9512c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import logging\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Configuration du logging pour TensorFlow et Transformers (moins verbeux)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235bedc3",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc2_'></a>[Chargement des données](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71eb2104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully:\n",
      "Train samples: 10000\n",
      "Validation samples: 3000\n",
      "Test samples: 238738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeBonCassoulet\\AppData\\Local\\Temp\\ipykernel_12712\\2464942598.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[\"cleaned_text\"].fillna(\"\", inplace=True)\n",
      "C:\\Users\\LeBonCassoulet\\AppData\\Local\\Temp\\ipykernel_12712\\2464942598.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  val_df[\"cleaned_text\"].fillna(\"\", inplace=True)\n",
      "C:\\Users\\LeBonCassoulet\\AppData\\Local\\Temp\\ipykernel_12712\\2464942598.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[\"cleaned_text\"].fillna(\"\", inplace=True)\n",
      "C:\\Users\\LeBonCassoulet\\AppData\\Local\\Temp\\ipykernel_12712\\2464942598.py:17: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df[\"sentiment\"].replace({\"negative\": 0, \"positive\": 1}).astype(int).to_list()\n",
      "C:\\Users\\LeBonCassoulet\\AppData\\Local\\Temp\\ipykernel_12712\\2464942598.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  val_df[\"sentiment\"].replace({\"negative\": 0, \"positive\": 1}).astype(int).to_list()\n",
      "C:\\Users\\LeBonCassoulet\\AppData\\Local\\Temp\\ipykernel_12712\\2464942598.py:25: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_df[\"sentiment\"].replace({\"negative\": 0, \"positive\": 1}).astype(int).to_list()\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_PATH = \"./train_data.csv\"\n",
    "VAL_DATA_PATH = \"./validation_data.csv\"\n",
    "TEST_DATA_PATH = \"./test_data.csv\"\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH).sample(10000)\n",
    "val_df = pd.read_csv(VAL_DATA_PATH).sample(3000)\n",
    "test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "\n",
    "# Handle potential NaN values in 'cleaned_text' that might result from preprocessing\n",
    "train_df[\"cleaned_text\"].fillna(\"\", inplace=True)\n",
    "val_df[\"cleaned_text\"].fillna(\"\", inplace=True)\n",
    "test_df[\"cleaned_text\"].fillna(\"\", inplace=True)\n",
    "\n",
    "\n",
    "X_train = train_df[\"cleaned_text\"].to_list()\n",
    "y_train = (\n",
    "    train_df[\"sentiment\"].replace({\"negative\": 0, \"positive\": 1}).astype(int).to_list()\n",
    ")\n",
    "X_val = val_df[\"cleaned_text\"].to_list()\n",
    "y_val = (\n",
    "    val_df[\"sentiment\"].replace({\"negative\": 0, \"positive\": 1}).astype(int).to_list()\n",
    ")\n",
    "X_test = test_df[\"cleaned_text\"].to_list()\n",
    "y_test = (\n",
    "    test_df[\"sentiment\"].replace({\"negative\": 0, \"positive\": 1}).astype(int).to_list()\n",
    ")\n",
    "\n",
    "print(\"Data loaded successfully:\")\n",
    "print(f\"Train samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb12d1",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc3_'></a>[Préparation pour BERT](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1370d056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Experiment: Tweet Sentiment Analysis - BERT Models\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = \"Tweet Sentiment Analysis - BERT Models\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "print(f\"MLflow Experiment: {EXPERIMENT_NAME}\")\n",
    "\n",
    "# --- 1. Paramètres et Données ---\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MAX_LENGTH = 16\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 6\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af26d02",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc3_1_'></a>[Création d'un Tokenizer](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e9fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exemple d'encodage (première phrase d'entraînement):\n",
      "input_ids: [101, 9379, 2154, 5199, 102, 0, 0, 0, 0, 0]...\n",
      "attention_mask: [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]...\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "def encode_texts(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=False,\n",
    "        return_tensors=\"tf\",\n",
    "    )\n",
    "\n",
    "\n",
    "train_encodings = encode_texts(X_train)\n",
    "val_encodings = encode_texts(X_val)\n",
    "test_encodings = encode_texts(X_test)\n",
    "\n",
    "# Conversion en tf.data.Dataset pour l'efficacité\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train))\n",
    "    .shuffle(len(X_train))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "val_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((dict(val_encodings), y_val))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "print(\"\\nExemple d'encodage (première phrase d'entraînement):\")\n",
    "for key, value in train_encodings.items():\n",
    "    print(f\"{key}: {value[0].numpy().tolist()[:10]}...\")  # Affiche les 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29263a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Construction modèle BERT pour Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee30981",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=2\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=2e-5)\n",
    "loss = SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n",
    "\n",
    "# Prepare TensorFlow datasets\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train))\n",
    "    .shuffle(1000)\n",
    "    .batch(16)\n",
    ")\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(\n",
    "    16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35ea075",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cfd3e4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc4_1_'></a>[MLFlow Setup](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d8dfcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow experiment set to: 'Tweet Sentiment Analysis - BERT Models'\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = \"Tweet Sentiment Analysis - BERT Models\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "print(f\"MLflow experiment set to: '{EXPERIMENT_NAME}'\")\n",
    "MODEL_ARTIFACT_PATH_BERT = \"bert-model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f08f6d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc4_2_'></a>[Entrainement du modèle avec MLFlow](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ad619",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/23 15:51:42 WARNING mlflow.tensorflow: Encountered unexpected error while inferring batch size from training dataset: The layer \"tf_bert_for_sequence_classification_3\" has never been called and thus has no defined input shape. Note that the `input_shape` property is only available for Functional and Sequential models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Démarrage de l'entraînement ---\n",
      "Epoch 1/6\n",
      "625/625 [==============================] - 364s 563ms/step - loss: 0.5330 - accuracy: 0.7257 - val_loss: 0.5103 - val_accuracy: 0.7410\n",
      "Epoch 2/6\n",
      "625/625 [==============================] - 384s 614ms/step - loss: 0.3872 - accuracy: 0.8258 - val_loss: 0.5308 - val_accuracy: 0.7540\n",
      "Epoch 3/6\n",
      "625/625 [==============================] - 438s 701ms/step - loss: 0.2494 - accuracy: 0.8990 - val_loss: 0.7311 - val_accuracy: 0.7420\n",
      "Epoch 4/6\n",
      "625/625 [==============================] - 434s 694ms/step - loss: 0.1330 - accuracy: 0.9522 - val_loss: 0.9148 - val_accuracy: 0.7540\n",
      "Epoch 5/6\n",
      "625/625 [==============================] - 427s 684ms/step - loss: 0.0814 - accuracy: 0.9717 - val_loss: 1.0594 - val_accuracy: 0.7520\n",
      "Epoch 6/6\n",
      "625/625 [==============================] - 355s 568ms/step - loss: 0.0630 - accuracy: 0.9776 - val_loss: 1.1463 - val_accuracy: 0.7537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/23 16:31:44 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='16' for run ID='009965bbf53a4504929fe370ffca7b72'. Attempted logging new value 'None'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Entraînement terminé ---\n",
      "\n",
      "--- Évaluation sur le jeu de test ---\n",
      " 4818/14922 [========>.....................] - ETA: 19:48 - loss: 1.1212 - accuracy: 0.7582"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# --- 5. Évaluation ---\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Évaluation sur le jeu de test ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRésultats du test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metrics(\n\u001b[0;32m     26\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\LeBonCassoulet\\Documents\\GitHub\\OpenClassrooms\\Projet_7\\.venv\\lib\\site-packages\\transformers\\modeling_tf_utils.py:1234\u001b[0m, in \u001b[0;36mTFPreTrainedModel.evaluate\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mevaluate)\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1233\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LeBonCassoulet\\Documents\\GitHub\\OpenClassrooms\\Projet_7\\.venv\\lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\LeBonCassoulet\\Documents\\GitHub\\OpenClassrooms\\Projet_7\\.venv\\lib\\site-packages\\tf_keras\\src\\engine\\training.py:2292\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2288\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   2289\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2290\u001b[0m             ):\n\u001b[0;32m   2291\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 2292\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2293\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2294\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2295\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2296\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2297\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2299\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2300\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LeBonCassoulet\\Documents\\GitHub\\OpenClassrooms\\Projet_7\\.venv\\lib\\site-packages\\tf_keras\\src\\engine\\training.py:4100\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[1;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[1;32m-> 4100\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   4102\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\LeBonCassoulet\\Documents\\GitHub\\OpenClassrooms\\Projet_7\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\LeBonCassoulet\\Documents\\GitHub\\OpenClassrooms\\Projet_7\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\LeBonCassoulet\\Documents\\GitHub\\OpenClassrooms\\Projet_7\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\LeBonCassoulet\\Documents\\GitHub\\OpenClassrooms\\Projet_7\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LeBonCassoulet\\Documents\\GitHub\\OpenClassrooms\\Projet_7\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\LeBonCassoulet\\Documents\\GitHub\\OpenClassrooms\\Projet_7\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\LeBonCassoulet\\Documents\\GitHub\\OpenClassrooms\\Projet_7\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\LeBonCassoulet\\Documents\\GitHub\\OpenClassrooms\\Projet_7\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\LeBonCassoulet\\Documents\\GitHub\\OpenClassrooms\\Projet_7\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"DistilBERT_FineTuning_CPU\") as run:\n",
    "    mlflow.log_param(\"model_name\", MODEL_NAME)\n",
    "    mlflow.log_param(\"max_length\", MAX_LENGTH)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"train_samples\", len(X_train))\n",
    "    mlflow.log_param(\"val_samples\", len(X_val))\n",
    "    mlflow.log_param(\"test_samples\", len(X_test))\n",
    "\n",
    "    print(\"\\n--- Démarrage de l'entraînement ---\")\n",
    "    mlflow.tensorflow.autolog(\n",
    "        log_models=False,\n",
    "        log_input_examples=False,\n",
    "        log_model_signatures=False,\n",
    "    )\n",
    "\n",
    "    history = model.fit(train_dataset, epochs=EPOCHS, validation_data=val_dataset)\n",
    "    print(\"--- Entraînement terminé ---\")\n",
    "\n",
    "    # --- 5. Évaluation ---\n",
    "    print(\"\\n--- Évaluation sur le jeu de test ---\")\n",
    "    results = model.evaluate(test_dataset, batch_size=BATCH_SIZE, return_dict=True)\n",
    "    print(f\"Résultats du test: {results}\")\n",
    "    mlflow.log_metrics(\n",
    "        {\"test_loss\": results[\"loss\"], \"test_accuracy\": results[\"accuracy\"]}\n",
    "    )\n",
    "\n",
    "    # --- 6. Sauvegarde du Modèle et du Tokenizer avec MLflow ---\n",
    "\n",
    "    print(\"\\n--- Sauvegarde du modèle et du tokenizer avec MLflow ---\")\n",
    "    mlflow.transformers.log_model(\n",
    "        transformers_model={\n",
    "            \"model\": model,\n",
    "            \"tokenizer\": tokenizer,\n",
    "        },\n",
    "        artifact_path=\"bert_sentiment_model\",\n",
    "        input_example=X_train[:5],\n",
    "    )\n",
    "\n",
    "    print(f\"MLflow Run ID: {run.info.run_id}\")\n",
    "    print(\n",
    "        f\"Modèle et Tokenizer sauvegardés dans MLflow run sous 'bert_sentiment_model'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd864511",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc6_2_'></a>[Evaluation du modèle sur les données de Test](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89112ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exemple de prédiction avec le modèle chargé depuis MLflow ---\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      "Tweet: This is an amazing flight!\n",
      "  Probabilités (Négatif, Non-Négatif/Positif): [0.27767384 0.72232616]\n",
      "  Sentiment Prédit: Non-Négatif/Positif (Classe: 1)\n",
      "\n",
      "Tweet: I will never fly with this airline again, horrible service.\n",
      "  Probabilités (Négatif, Non-Négatif/Positif): [0.5397522  0.46024784]\n",
      "  Sentiment Prédit: Négatif (Classe: 0)\n",
      "\n",
      "Tweet: The flight was okay, nothing special.\n",
      "  Probabilités (Négatif, Non-Négatif/Positif): [0.38441566 0.6155843 ]\n",
      "  Sentiment Prédit: Non-Négatif/Positif (Classe: 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Exemple de prédiction avec le modèle chargé depuis MLflow ---\")\n",
    "\n",
    "# Tokenization des exemples\n",
    "sample_encodings = encode_texts(X_test)\n",
    "\n",
    "# Prédictions (logits)\n",
    "predictions = model.predict(dict(sample_encodings))\n",
    "logits = predictions.logits\n",
    "\n",
    "# Conversion des logits en probabilités et en classes prédites\n",
    "probabilities = tf.nn.softmax(logits, axis=-1).numpy()\n",
    "predicted_classes = np.argmax(probabilities, axis=1)\n",
    "\n",
    "for tweet, true, prob, pred_class in zip(\n",
    "    X_test, y_test, probabilities, predicted_classes\n",
    ")[:50]:\n",
    "    sentiment = \"Non-Négatif/Positif\" if pred_class == 1 else \"Négatif\"\n",
    "    print(f\"\\nTweet: {tweet}\")\n",
    "    print(f\"  Probabilités (Négatif, Non-Négatif/Positif): {prob}\")\n",
    "    print(f\"  Sentiment Prédit: {sentiment} | 'Vrai' Sentiment : {true}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
